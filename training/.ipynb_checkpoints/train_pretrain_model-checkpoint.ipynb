{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34988009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: C:\\Users\\Pop\\Documents\\GitHub\\utcc_independent_study\\training\\..\\data\\300_data_pop.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "data_dir = os.path.join(current_dir, \"..\", \"data\")\n",
    "data_path = os.path.join(data_dir, \"300_data_pop.xlsx\")\n",
    "model_dir = os.path.join(current_dir, \"..\", \"model\")\n",
    "\n",
    "print(\"Data path:\", data_path)\n",
    "\n",
    "def calculate_sum_score(df):\n",
    "    df['score'] = df['creditability'] + df['content'] + df['expression']\n",
    "    return df\n",
    "    \n",
    "def norm_score(data):\n",
    "    score_min = data['score'].min()\n",
    "    score_max = data['score'].max()\n",
    "    data['score_norm'] = (data['score'] - score_min) / (score_max - score_min)\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel(data_path)\n",
    "data = calculate_sum_score(data)\n",
    "data = norm_score(data)\n",
    "data = data[['comment', 'score_norm']]\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c447bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298ff9e2ecf84a36b7c866ba6b57070a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/2.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d956f285df094e5d9871d8f8b4790143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/419M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pythainlp/thainer-corpus-v2-base-model were not used when initializing CamembertForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at pythainlp/thainer-corpus-v2-base-model and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d879f3566c6446da3ea1fc68f55564d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3564988b71492fa3aaa0540832d85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)tencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472b5cdac6b74d6aa602c1a6146371bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f87f0c9e11423997a9584763305584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KoichiYasuoka/roberta-base-thai-spm-upos were not used when initializing RobertaForSequenceClassification: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at KoichiYasuoka/roberta-base-thai-spm-upos and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = 1 # regression\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model_name = \"pythainlp/thainer-corpus-v2-base-model\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = 1 # regression\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model_name = \"KoichiYasuoka/roberta-base-thai-spm-upos\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.num_labels = 1 # regression\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc618cfb",
   "metadata": {},
   "source": [
    "airesearch/wangchanberta-base-att-spm-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c80e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.019131021574139595\n",
      "Epoch: 2, Loss: 0.009090022067539394\n",
      "Epoch: 3, Loss: 0.009296075208112597\n",
      "Mean Squared Error: 0.0564\n",
      "Mean Absolute Error: 0.2018\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§à¸§ à¸ªà¹ˆà¸‡à¸à¹ˆà¸­à¸™à¸à¸³à¸«à¸™à¸”4à¸§à¸±à¸™à¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸•à¸²à¸¡à¸›à¸ à¸£à¸²à¸„à¸²à¸”à¸µà¹„à¸¡à¹ˆà¹à¸žà¸‡ à¹€à¸„à¸¢à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§à¸Šà¸­à¸š à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸¥à¸´à¸›à¹€à¸›à¸·à¹‰à¸­à¸™à¹à¸¡à¸ªà¹„à¸”à¹‰à¸”à¸µ\n",
      "actual: 0.8888888955116272\n",
      "predicted: 1.1526739597320557\n",
      "\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸„à¹ˆà¸° à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸¹à¸à¸”à¸µ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸‡à¹ˆà¸²à¸¢à¸¡à¸²à¸ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸¥à¸·à¹ˆà¸™ à¹„à¸§à¸„à¹ˆà¸° à¸à¹‡à¸–à¸™à¸±à¸”à¸”à¸µ à¹„à¸§à¹‰à¸ˆà¸°à¸­à¸¸à¸”à¸«à¸™à¸¸à¸™à¹ƒà¸«à¸¡à¹ˆà¸™à¸°à¸„à¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.1065387725830078\n",
      "\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸‚à¸­à¸‡à¹„à¸”à¹‰à¸•à¸£à¸‡à¸£à¸¹à¸›à¸•à¸£à¸‡à¸›à¸à¸—à¸±à¹‰à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸—à¸±à¹‰à¸‡à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œ à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸²à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸šà¸²à¸‡à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹à¸•à¹ˆà¸à¹‡à¸ªà¸¡à¸à¸±à¸šà¸£à¸²à¸„à¸²à¸™à¸µà¹‰à¸„à¹ˆà¸° à¸¡à¸²à¸—à¸µà¹ˆà¹€à¸¡à¸²à¸ªà¹Œà¹à¸™à¸°à¸™à¸³à¸§à¹ˆà¸²à¹ƒà¸«à¹‰à¸«à¸²à¹à¸œà¹ˆà¸™à¸£à¸­à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸”à¹‰à¸§à¸¢à¸™à¸°à¸„à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸„à¸£à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ à¹€à¸žà¸£à¸²à¸°à¸–à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸±à¸šà¹‚à¸•à¹Šà¸°à¹€à¸›à¸¥à¹ˆà¸²à¹†à¹€à¸¥à¹€à¸‹à¸­à¸£à¹Œà¸ˆà¸°à¹„à¸›à¸•à¸´à¸”à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸£à¸²à¸„à¸²à¹à¸¥à¸°à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸„à¹ˆà¸°ðŸ˜Š\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0861258506774902\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸²à¸à¹† à¸à¸²à¸£à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸ˆà¸²à¸à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹† à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡âœ¨\n",
      "actual: 0.8888888955116272\n",
      "predicted: 1.031291127204895\n",
      "\n",
      "comment: à¸”à¸µà¸„à¹ˆà¸° à¹à¸•à¹ˆà¹€à¸§à¸¥à¸²à¹‚à¸”à¸™à¸à¹‡à¸žà¸­à¸ªà¸‡à¹ˆà¸²à¸¢à¹€à¸à¸´à¸™à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¹‡à¹ƒà¸Šà¹‰à¸‡à¹ˆà¸²à¸¢ à¸žà¸à¸žà¸²à¸‡à¹ˆà¸²à¸¢à¸ªà¸°à¸”à¸§à¸à¸„à¹ˆà¸° à¹à¸šà¸•à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸­à¸¶à¸”à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹€à¸›à¸´à¸”à¸›à¸´à¸”à¸à¸²à¸à¹‡à¹„à¸¡à¹ˆà¸à¹Šà¸­à¸à¹à¸à¹Šà¸‡ à¸‚à¸™à¸ªà¹ˆà¸‡à¹„à¸§à¸„à¹ˆà¸°\n",
      "actual: 0.8888888955116272\n",
      "predicted: 1.0248957872390747\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸¥à¸±à¸à¸©à¸“à¹Œà¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸•à¸²à¸¡à¸›à¸ à¹à¸•à¹ˆà¸•à¸±à¸§à¹€à¸£à¸·à¸­à¸™à¹ƒà¸«à¸à¹ˆà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ à¹à¸•à¹ˆà¸•à¸­à¸šà¹€à¹€à¸Šà¹‡à¸—à¸Šà¹‰à¸²à¸¡à¸²à¸ à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸­à¸¥à¸­à¸‡à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µà¸‚à¸™à¸²à¸”à¹„à¸«à¸™\n",
      "actual: 0.5555555820465088\n",
      "predicted: 1.0153114795684814\n",
      "\n",
      "comment: à¸œà¸¡à¹ƒà¸Šà¹‰iPhone14 Pro Max 512, à¸¡à¸µà¹€à¸„à¸ªà¸‚à¸­à¸‡casetify. à¹à¸¡à¹ˆà¹€à¸«à¸¥à¹‡à¸à¸ˆà¸±à¸šà¸”à¸µà¸„à¸£à¸±à¸š à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸µà¸¡à¸²à¸ à¹à¸•à¹ˆ!!! à¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡ à¸–à¸­à¸”à¹€à¸„à¸ªà¸¡à¸²à¸Šà¸²à¸£à¹Œà¸ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¸¡à¸²à¸¢à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¸–à¸·à¸­à¸ªà¸°à¸§à¹ˆà¸²à¹€à¸­à¸²à¸¡à¸²à¸§à¸²à¸‡à¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œà¹€à¸‰à¸¢à¹† à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸²à¸„à¸¸à¸“à¸¡à¸µà¹€à¸„à¸ªà¸«à¸™à¸² 1à¸”à¸²à¸§à¹ƒà¸«à¹‰à¸à¸²à¸£à¸šà¸”à¸µà¹„à¸‹à¸™à¹Œ à¸™à¸­à¸à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸”à¸²à¸§à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 1.0140187740325928\n",
      "\n",
      "comment: à¸¥à¸­à¸‡à¹à¸¥à¹‰à¸§à¹‚à¸­à¹€à¸„.à¹„à¸Ÿà¸•à¸´à¸”à¸—à¸¸à¸à¸”à¸§à¸‡.à¸£à¸µà¹‚à¸¡à¸—à¹ƒà¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹‚à¸­à¹€à¸„à¸¡à¸µà¸–à¹ˆà¸²à¸™à¸•à¸´à¸´à¸”à¸¡à¸²à¹à¸¥à¹‰à¸§à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹€à¸¥à¸¢..à¹„à¸Ÿà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¸‡à¸²à¸¡. à¹à¸žà¹‡à¸„à¸‚à¸­à¸‡à¸«à¹ˆà¸­à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢.à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸š. à¸•à¸£à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡à¸‹à¸·à¹‰à¸­. à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸µà¹‚à¸—à¸£à¹à¸ˆà¹‰à¸‡à¸à¹ˆà¸­à¸™à¹€à¸‚à¹‰à¸²à¸¡à¸²à¸ªà¹ˆà¸‡...\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.013648509979248\n",
      "\n",
      "comment: à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸¡à¸²à¸ªà¸±à¸à¸žà¸±à¸à¸”à¸µà¸¡à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¹ˆà¹à¸•à¸à¹€à¸šà¸ªà¸«à¸™à¸±à¸à¸Ÿà¸±à¸‡à¹€à¸žà¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¸¡à¸²à¸à¸¡à¸µà¸•à¸³à¸«à¸™à¸´à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¸‚à¸­à¸šà¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£à¹à¸šà¸•à¸—à¸™à¸¡à¸²à¸à¸Šà¸²à¸£à¹Œà¸ˆ1à¸„à¸£à¸±à¹‰à¸‡à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¹„à¸”à¹‰à¸¡à¸²à¸§à¸±à¸™à¹à¸£à¸à¸ˆà¸™à¸–à¸¶à¸‡à¸§à¸±à¸™à¸™à¸µà¹‰à¹à¸šà¸•à¸¢à¸±à¸‡à¹€à¸«à¸¥à¸·à¸­à¸­à¸µà¸50à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0080275535583496\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸›à¸à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¹†à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡à¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸œ à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹†à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢ à¸¡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 1.0072466135025024\n",
      "\n",
      "comment: à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²: à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸”à¹‰à¸£à¸±à¸šà¹à¸¥à¹‰à¸§à¸ªà¹ˆà¸‡à¸¡à¸²à¸ˆà¸²à¸à¸•à¹ˆà¸²à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸‚à¸™à¸ªà¹ˆà¸‡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸—à¸°à¸™à¸¸à¸–à¸™à¸­à¸¡à¸”à¸µà¸¥à¸­à¸‡à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸”à¸µà¹‹à¸¢à¸§à¸‚à¸­à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸à¹ˆà¸­à¸™à¸™à¸°à¸„à¸°à¸§à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸µà¹à¸•à¹ˆà¸£à¸²à¸„à¸²à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9823421239852905\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸—à¸£à¸‡à¹€à¸—à¹ˆà¸”à¸µ à¸§à¸±à¸ªà¸”à¸¸à¸”à¸µ à¸šà¸²à¸‡à¸„à¸£à¸±à¹‰à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¢à¸±à¸‡à¸«à¸™à¹ˆà¸§à¸‡à¸šà¹‰à¸²à¸‡à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢ à¹à¸•à¹ˆà¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸ªà¸¡à¸£à¸²à¸„à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9716628789901733\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸‡à¸›à¸à¸„à¹ˆà¸° à¸¥à¸¹à¸à¸Šà¸­à¸šà¸¡à¸²à¸à¸„à¹ˆà¸°à¸¡à¸µà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œ à¸à¹‡à¸¡à¸µà¸ªà¸µà¸«à¸¥à¸²à¸¢à¸ªà¸µ à¹ƒà¸«à¹‰à¹€à¸¥à¸·à¸­à¸ à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œà¸‡à¹ˆà¸²à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9639133810997009\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸„à¹ˆà¸° à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸¹à¸”à¸µ à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡ à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¹† à¸„à¸£à¸±à¹‰à¸‡à¸•à¹ˆà¸­à¹„à¸›à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸° à¸ªà¸²à¸¢à¸ªà¸§à¸¢à¹† à¸™à¹ˆà¸²à¸£à¸±à¸à¹†\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.9607901573181152\n",
      "\n",
      "comment: à¹‚à¸­à¹€à¸„à¸™à¸°à¸„à¸°à¸à¹‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸Šà¸²à¸£à¹Œà¸ˆà¸à¸±à¸š Apple Watch à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹‚à¸­à¹€à¸„à¸­à¸¢à¸¹à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸§à¸£à¹‰à¸²à¸¢à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹€à¸£à¸·à¹ˆà¸­à¸‡à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹à¸žà¸‡à¹à¸•à¹ˆà¸‚à¹‰à¸­à¸”à¸µà¸à¹‡à¸„à¸·à¸­à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸žà¸£à¸µà¸­à¸­à¹€à¸”à¸­à¸£à¹Œà¸¡à¸µà¸‚à¸­à¸‡à¸žà¸£à¹‰à¸­à¸¡à¸ªà¹ˆà¸‡à¹€à¸¥à¸¢à¸™à¸µà¹ˆà¸„à¸·à¸­à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸•à¸±à¸§à¸™à¸µà¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸à¹‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸­à¸²à¸ˆà¸ˆà¸°à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸à¹‰à¸­à¸‡à¹à¸à¹Šà¸‡à¸„à¹Œà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸ˆà¸±à¸”à¹€à¸•à¹‡à¸¡à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.94661545753479\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸ à¸²à¸žà¸£à¸§à¸¡à¹‚à¸­à¹€à¸„à¹€à¸¥à¸¢ à¹„à¸”à¹‰à¸¡à¸µà¸¡ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸­à¸­à¸ à¸šà¸£à¸´à¸«à¸²à¸£à¹‚à¸”à¸¢à¹€ à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9329348206520081\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆà¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.9287043213844299\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹€à¸²à¸”à¸µà¸„à¹ˆà¸° à¸•à¸£à¸‡à¸›à¸ à¸ªà¹ˆà¸‡à¹„à¸§ à¹à¸•à¹ˆà¸«à¸±à¸1à¸”à¸²à¸§à¹€à¸žà¸£à¸²à¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Ÿà¹‰à¸²à¹„à¸›à¹à¸™à¹ˆà¸§à¹ˆà¸ªà¹„à¸”à¹‰à¸ªà¸£à¸‚à¸²à¸§à¸¡à¸²à¹à¸—à¸™ à¹à¸•à¹ˆà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸„à¹ˆà¸° à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¹†à¸”à¹‰à¸›à¸à¸•à¸´à¹€à¸¥à¸¢ à¹‚à¸­à¹€à¸„à¸¡à¸²à¸\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.8910606503486633\n",
      "\n",
      "comment: à¸ªà¸§à¸¢à¸”à¸µà¸„à¹ˆà¸°à¹à¸•à¹ˆà¹à¸šà¸•à¸«à¸¡à¸”à¹„à¸§à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹€à¸¥à¹ˆà¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸›à¹‡à¸™à¸”à¹‰à¸§à¸¢à¸‡à¸‡à¹†à¸™à¸´à¸ªà¸™à¸¶à¸‡à¹ƒà¸ªà¹ˆà¹à¸¥à¹‰à¸§à¸§à¸±à¸”à¹„à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸«à¸£à¸·à¸­à¹€à¸£à¸²à¸‡à¸‡à¹†à¹„à¸›à¹€à¸­à¸‡à¸à¹‰à¸­à¹„à¸¡à¹ˆà¸£à¸¸à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹à¸à¹ˆà¸£à¸²à¸„à¸²à¸„à¹ˆà¸°à¸¥à¸¹à¸à¸­à¸¢à¸²à¸à¹„à¸”à¹‰à¸à¹‰à¸­à¹€à¸¥à¸¢à¸ˆà¸±à¸”à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸”à¸¹à¸ªà¸±à¸à¸žà¸±à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸—à¸™à¸—à¸²à¸™à¸¡à¸±à¹‰à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8724506497383118\n",
      "\n",
      "comment: à¹ƒà¸«à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸‹à¹‰à¸³à¹à¸¥à¸°à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸„à¸£à¸š à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸ˆà¸±à¸”à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.8714621067047119\n",
      "\n",
      "comment: à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸” à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¸„à¹Œà¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸žà¸¥à¸‡à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.8558377623558044\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§ à¸Šà¸³à¸£à¸¸à¸”à¸„à¹ˆà¸° à¹à¸•à¸ à¸™à¹ˆà¸²à¸ˆà¸°à¸«à¹ˆà¸­à¹„à¸¡à¹ˆà¸”à¸µà¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸«à¹ˆà¸­à¸­à¸°à¹„à¸£à¹€à¸¥à¸¢ à¹ƒà¸ªà¹ˆà¹à¸„à¹ˆà¸–à¸¸à¸‡à¸¡à¸² à¹à¸šà¸šà¸™à¸µà¹‰à¸‚à¸­à¸‡à¸à¹‰à¸­à¸žà¸±à¸‡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸«à¸¡à¸”à¸ªà¸´à¸„à¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8428688645362854\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¸¥à¸³à¹‚à¸žà¸‡à¹€à¸¥à¸°à¹€à¸—à¸°à¸¡à¸²à¸à¸•à¸±à¹‰à¸‡à¹€à¹€à¸•à¹ˆà¹€à¹€à¸à¸° à¸•à¹‰à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¸¥à¸³à¹‚à¸žà¸‡à¸•à¸¥à¸­à¸”à¹€à¸§à¸¥à¸²à¸–à¸¶à¸‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸«à¸¥à¸¸à¸”à¸šà¹ˆà¸­à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8287729620933533\n",
      "\n",
      "comment: à¸•à¸´à¸”à¹†à¸«à¸¥à¸¸à¸”à¹†à¸‡à¸‡à¹† à¸Šà¸²à¸£à¹Œà¸ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡ à¹€à¸£à¸²à¹ƒà¸Šà¹‰à¹„à¸­à¹‚à¸Ÿà¸™11 à¸™à¸­à¸¢ à¸•à¸­à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆà¹€à¸žà¸£à¸²à¸°2à¹€à¸¡à¸•à¸£à¸£à¸¶à¸›à¹ˆà¸²à¸§ à¸–à¹‰à¸²1à¹€à¸¡à¸•à¸£à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² à¹à¸žà¹‡à¸„à¸”à¸µ à¸ªà¹ˆà¸‡à¹„à¸§\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8138526082038879\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸”à¸³à¹„à¸”à¹‰à¸ªà¸µà¸™à¹‰à¸³à¹€à¸‡à¸´à¸™ à¸šà¸­à¸à¸žà¸™à¸±à¸à¸‡à¸²à¸™à¸ªà¹ˆà¸‡à¸œà¸´à¸” à¹à¸•à¹ˆà¸”à¸¹à¸ˆà¸²à¸à¸£à¸µà¸§à¸´à¸§à¸ªà¹ˆà¸‡à¸œà¸´à¸”à¸šà¹ˆà¸­à¸¢à¹„à¸›à¸™à¸°à¸„à¸°...\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.8090070486068726\n",
      "\n",
      "comment: à¸—à¸±à¸à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸•à¸­à¸š à¹ƒà¸™à¸£à¸¹à¸›à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸ªà¸²à¸¢à¹à¸ˆà¹Šà¸ª à¸‚à¸­à¸‡à¸¡à¸²à¸–à¸¶à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸”à¸¹à¹à¸¥\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.80841463804245\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¸ à¸²à¸¢à¹ƒà¸™à¹„à¸¡à¹ˆà¸à¸µà¹ˆà¸§à¸±à¸™ à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸ªà¹ˆà¸‡à¸ˆà¸²à¸à¹ƒà¸™à¹„à¸—à¸¢à¹€à¸¥à¸¢ à¸žà¸±à¸ªà¸”à¸¸à¸à¸¥à¹ˆà¸­à¸‡ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸à¸°à¸‹à¸­à¸‡à¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸² à¹à¸•à¹ˆà¸„à¸²à¸”à¸§à¹ˆà¸²à¸™à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸›à¸à¸•à¸´ à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸­à¸°à¹„à¸£ à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆà¹à¸¥à¸°à¸ˆà¸°à¸à¸¥à¸±à¸šà¸¡à¸²à¸‹à¸·à¹‰à¸­à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 0.7874276638031006\n",
      "\n",
      "comment: à¹à¸¢à¹ˆ à¸£à¹‰à¸­à¸™à¸¡à¸²à¸à¹€à¸§à¸¥à¸²à¸Šà¸²à¸£à¹Œà¸ˆ à¸¡à¸µtype-c à¹à¸•à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸­à¸­à¸à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸¡à¸µà¹„à¸§à¹‰à¹€à¸žà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7747921347618103\n",
      "\n",
      "comment: à¸‚à¸­à¸‡à¸žà¸¶à¹ˆà¸‡à¹„à¸”à¹‰à¸¡à¸²à¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™à¹ƒà¸Šà¹‰à¸•à¸­à¸™à¹€à¸Šà¹‰à¸²à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸œà¸¡à¸£à¸­à¸‚à¸­à¸‡à¸•à¸±à¹‰à¸‡à¸™à¸²à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¸‚à¸§à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7743167281150818\n",
      "\n",
      "comment: à¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸–à¸­à¸”à¹€à¸‚à¹‰à¸²à¸–à¸­à¸”à¸­à¸­à¸à¸¢à¸²à¸ à¹‚à¸—à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸ªà¸–à¸µà¸¢à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7370508313179016\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸•à¸²à¸¡à¸£à¸²à¸„à¸² à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¸§ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7256016135215759\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸›à¸ªà¸µà¸¡à¹ˆà¸§à¸‡ à¹à¸•à¹ˆà¸ªà¸µà¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸­à¸­à¸à¹€à¸›à¹‡à¸™à¸ªà¸µà¸Ÿà¹‰à¸² à¹„à¸¡à¹ˆà¸–à¸¹à¸à¹ƒà¸ˆà¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µ à¹à¸•à¹ˆà¸„à¸µà¸¢à¹Œà¸šà¸­à¸£à¹Œà¸”à¸ªà¸¥à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¸›à¸¸à¹ˆà¸¡à¹„à¸«à¸™ à¸”à¸¹à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹à¸ˆà¹‰à¸‡ à¹à¸•à¹ˆà¸à¸”à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¹ˆà¸°  à¸‡à¸‡à¸¡à¸²à¸ à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¹€à¸£à¹‡à¸§à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7196069955825806\n",
      "\n",
      "comment: à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸”à¸”à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¸²à¸„à¸²à¹„à¸¡à¸²à¹€à¸à¸´à¸™à¸£à¹‰à¸­à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸à¸³à¸¥à¸±à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸±à¸‡à¹„à¸›à¹„à¸¡à¹ˆà¹€à¸šà¸²à¹„à¸› à¹à¸•à¹ˆà¹€à¸šà¸ªà¸à¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸à¸£à¸µà¸¢à¸”à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7175397276878357\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆ à¹„à¸”à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡ à¹à¸žà¹‡à¸„à¹€à¸à¸ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢à¹à¸•à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¥à¸à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸² à¸£à¸²à¸„à¸²à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹‚à¸”à¸¢à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡ à¹‚à¸­à¸à¸²à¸ªà¸«à¸™à¹‰à¸²à¸„à¹ˆà¸­à¸¢à¸‹à¸·à¹‰à¸­à¹€à¸žà¸´à¹ˆà¸¡à¸™à¸°à¸„à¸£à¸±à¸š\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.7149360179901123\n",
      "\n",
      "comment: à¹à¸žà¹Šà¸„à¸‚à¸­à¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸ à¸à¸¥à¹ˆà¸­à¸‡à¸ªà¸²à¸¢à¸šà¸¸à¸šà¹„à¸›à¹€à¸à¸·à¸­à¸šà¸„à¸£à¸¶à¹ˆà¸‡ à¸ªà¸±à¹ˆà¸‡à¸„à¸£à¸±à¹‰à¸‡à¸™à¸µà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¸ˆà¸°à¹„à¸¡à¹ˆà¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸¥à¹‰à¸§\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7022454142570496\n",
      "\n",
      "comment: à¸à¹ˆà¸­à¸™à¸‹à¸·à¹‰à¸­à¸à¹‡à¸­à¸¸à¸•à¸ªà¹ˆà¸²à¸«à¹Œà¸”à¸¹à¹ƒà¸™à¸£à¸µà¸§à¸´à¸§à¹à¸¥à¹‰à¸§à¸™à¸° à¸à¹‡à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸›à¸¸à¹ˆà¸¡à¹„à¸—à¸¢à¹à¸—à¹‰ à¹à¸•à¹ˆà¸žà¸­à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸à¹‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸¡à¸²à¸ à¹€à¸›à¹‡à¸™à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹„à¸—à¸¢à¸‹à¸°à¸‡à¸±à¹‰à¸™ à¸‹à¸¶à¹ˆà¸‡à¸žà¸­à¸•à¸´à¸”à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹à¸¥à¹‰à¸§ à¸¡à¸±à¸™à¸¡à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸¥à¸²à¸‡à¸„à¸·à¸™ à¸¥à¸³à¸šà¸²à¸à¹à¸¥à¸°à¸«à¸‡à¸¸à¸”à¸«à¸‡à¸´à¸”à¸¡à¸²à¸ à¸‹à¸·à¹‰à¸­à¹à¸šà¸šà¸¡à¸µà¹„à¸Ÿ à¹à¸•à¹ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿ à¸Šà¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸—à¸µà¹ˆà¹„à¸£à¹‰à¸„à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸ˆà¸£à¸´à¸‡ à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸ˆà¸£à¸´à¸‡à¹† à¸£à¸¹à¹‰à¸‡à¸µà¹‰ à¸‹à¸·à¹‰à¸­à¸£à¹‰à¸²à¸™à¸­à¸·à¹ˆà¸™ à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¹à¸›à¹‰à¸™à¹„à¸—à¸¢à¹à¸—à¹‰à¸”à¸µà¸à¸§à¹ˆà¸²\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.700678825378418\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸‚à¸²à¸§ à¹à¸•à¹ˆà¸ªà¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¸¡à¸²à¹à¸—à¸™ à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸–à¸²à¸¡à¸à¹ˆà¸­à¸™ à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸±à¸™à¸ªà¸¡à¸±à¸¢ à¸ˆà¸±à¸šà¸–à¸™à¸±à¸”à¸¡à¸·à¸­\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6981444954872131\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸Šà¹‰à¸²à¸¡à¸² à¸£à¸­à¸¡à¸²à¸„à¸£à¸¶à¹ˆà¸‡à¹€à¸”à¸·à¸­à¸™à¸žà¸¶à¹ˆà¸‡à¸ˆà¸°à¹„à¸”à¹‰ à¸–à¹‰à¸²à¹ƒà¸„à¸£à¸£à¸µà¸šà¹„à¸›à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.6752381324768066\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¢à¸´à¸™à¸™à¸´à¸”à¸™à¸¶à¸‡à¹à¸•à¹ˆà¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¹‰à¸²à¸™à¹ƒà¸™à¸¢à¸±à¸‡à¹‚à¸­à¹€à¸„ à¹€à¸”à¸µà¹‹à¸¢à¸§à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸›à¸à¸•à¸´à¸¡à¸±à¹Šà¸¢\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.6549298167228699\n",
      "\n",
      "comment: à¸«à¸¹à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¸¢à¸´à¸™à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¹„à¸¡à¹ˆà¸”à¸µà¹€à¸¥à¸¢ à¸à¸²à¸£à¹à¸žà¸„à¸à¸¥à¹ˆà¸­à¸‡à¸à¹‡à¹„à¸¡à¹ˆà¸ªà¸¡à¸›à¸£à¸°à¸à¸­à¸š à¸‚à¸²à¸”\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6421765685081482\n",
      "\n",
      "comment: à¸ªà¸±à¸‡à¹€à¸à¸•à¸”à¸µà¹†à¸¡à¸µà¸£à¸­à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸–à¸¹à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§à¸”à¹‰à¸§à¸¢ à¸¡à¸±à¸™à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¹à¸¢à¹ˆà¹à¸¥à¸°à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸™à¹ˆà¸°à¸„à¹ˆà¸° à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹à¸£à¸à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸ˆà¸°à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹„à¸”à¹‰à¸£à¸¶à¹€à¸›à¸¥à¹ˆà¸²ðŸ¥²ðŸ˜­\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.629703938961029\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸§à¸±à¸™à¹€à¸”à¸µà¸¢à¸§à¸–à¸¶à¸‡à¸«à¸±à¸1à¸„à¸°à¹à¸™à¸™ à¹€à¸žà¸£à¸²à¸°à¹„à¸¡à¹ˆà¸«à¹‰à¸­à¸à¸±à¸™à¸›à¸£à¸°à¹à¸—à¸ à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸„à¸¸à¹‰à¸¡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.6227008700370789\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸‚à¸­à¸‡à¸¡à¸²à¸§à¸±à¸™à¸—à¸µà¹ˆ13 à¸§à¸±à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸™à¸„à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§à¸à¹‡à¸”à¸±à¸šà¹„à¸›à¹€à¸¥à¸¢ à¹€à¸›à¸´à¸”à¹„à¸¡à¹ˆà¸•à¸´à¸”à¸­à¸µà¸à¹€à¸¥à¸¢ à¸¥à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¹à¸¥à¹‰à¸§à¸à¹‡à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.5867133736610413\n",
      "\n",
      "comment: à¸Šà¸­à¸šà¸¡à¸²à¸à¹€à¸¥à¸¢à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸­à¸¢à¸ªà¸µà¹€à¸­à¹ˆà¸¢à¸”à¸µà¹„à¸›à¸«à¸¡à¸”à¸”à¸¹à¹€à¸£à¸µà¸¢à¸šà¹à¸•à¹ˆà¸ªà¸§à¸¢à¸ªà¸µà¸”à¸³à¸ªà¸§à¸¢à¸¡à¸²à¸à¸ªà¸µà¹€à¸—à¸²à¸à¹‡à¸ªà¸§à¸¢à¹„à¸§à¹‰à¸ˆà¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¹€à¸—à¸²à¸­à¸µà¸à¸„à¹ˆà¸°à¸—à¸£à¸‡à¸ªà¸§à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¹€à¸ˆà¹‡à¸šà¸«à¸¹\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.5562992095947266\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸«à¸¹à¸Ÿà¸±à¸‡à¸¡à¸²à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.5272573828697205\n",
      "\n",
      "comment: à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸„à¸™à¸¥à¸°à¸£à¸¸à¹ˆà¸™à¸à¸±à¸™à¸Šà¸²à¸ˆà¹„à¸¡à¹ˆà¹ƒà¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.5104205012321472\n",
      "\n",
      "comment: à¸§à¸±à¸ªà¸”à¸¸à¸à¹Šà¸­à¸‡à¹à¸à¹Šà¸‡à¸¡à¸²à¸ à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¹„à¸”à¹‰à¸ªà¸µà¸Ÿà¹‰à¸²\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.4515591561794281\n",
      "\n",
      "comment: à¸›à¸¸à¹ˆà¸¡à¸à¸”à¸”à¹‰à¸²à¸™à¸‹à¹‰à¸²à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸•à¸´à¸”à¹†à¸­à¸°à¹„à¸£à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸¥à¸‡ à¹€à¸¥à¸·à¹ˆà¸­à¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹„à¸› à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸•à¸´à¸”à¸›à¸à¸•à¸´à¹à¸•à¹ˆà¹„à¸§à¹„à¸Ÿà¸¢à¸±à¸‡à¸•à¹ˆà¸­à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸¢ à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹€à¸‡à¸´à¸™\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.41048625111579895\n",
      "\n",
      "comment: à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸šà¸²â€‹\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.3785873055458069\n",
      "\n",
      "comment: à¸Šà¸²à¸£à¹Œà¸ˆà¸Šà¹‰à¸²à¸¡à¸²à¸à¸„à¹ˆà¸° à¸Šà¸²à¸£à¹Œà¸ˆà¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸™à¸­à¸™ à¸•à¸·à¹ˆà¸™à¸¡à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸•à¹‡à¸¡à¹€à¸¥à¸¢\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.37028107047080994\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸„à¸²à¸”à¸«à¸§à¸±à¸‡ à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹à¸¢à¹ˆà¸¡à¸²à¸\n",
      "actual: 0.0\n",
      "predicted: 0.351113885641098\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹„à¸¡à¹ˆà¹„à¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.3486069440841675\n",
      "\n",
      "comment: à¹ƒà¸ªà¹ˆà¸‹à¸´à¸¡à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸±à¸à¸à¸²à¸“ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸¥à¸‡à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸•à¸­à¸šà¸Šà¹‰à¸²\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.32970961928367615\n",
      "\n",
      "comment: à¸”à¸µà¸¡à¸²à¸à¹†\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.3278040885925293\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸²à¸¢à¸Šà¸²à¸£à¹Œà¸•à¸ªà¹ˆà¸‡à¸¡à¸²à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.30089297890663147\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸‹à¸·à¹‰à¸­\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.2306874394416809\n",
      "\n",
      "comment: à¸•à¸°à¸¡à¸¸à¸•à¸°à¸¡à¸´à¸™à¹ˆà¸²à¸£à¸±à¸  à¹€à¸ªà¸µà¸¢à¸‡à¹à¸ˆà¹ˆà¸¡à¸”à¸µà¸„à¹ˆà¸°  à¸Šà¸­à¸šà¸¡à¸²à¸  à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.17667599022388458\n",
      "\n",
      "comment: à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸£à¸²à¸„à¸²\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.11662694066762924\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µà¹€à¸à¸´à¸™à¸£à¸²à¸„à¸² à¸•à¹‰à¸­à¸‡à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.06343353539705276\n",
      "\n",
      "comment: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸„à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.0174082200974226\n",
      "\n",
      "comment: à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.1111111119389534\n",
      "predicted: -0.019445376470685005\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž\n",
      "actual: 0.2222222238779068\n",
      "predicted: -0.02920049987733364\n",
      "\n",
      "comment: à¸‚à¸™à¸ªà¹ˆà¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: -0.05591996759176254\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¹€à¸¥à¸¢\n",
      "actual: 0.1111111119389534\n",
      "predicted: -0.13580982387065887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model1\n",
    "tokenizer = tokenizer1\n",
    "\n",
    "# Define your loss function\n",
    "loss_fn = torch.nn.MSELoss()  # Change loss function to L1Loss for regression\n",
    "\n",
    "# Move your model to the device (CPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Set up gradient accumulation\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Define batch and epochs\n",
    "batch_size = 16  # Reduced batch size\n",
    "num_epochs = 3\n",
    "\n",
    "# Tokenize data and create dataloader\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    train_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=200,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "labels = torch.tensor(train_data['score_norm'].values, dtype=torch.float32)  # Convert labels to float32\n",
    "dataset = TensorDataset(encoded_data['input_ids'], encoded_data['attention_mask'], labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Fine-tune the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        step += 1\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {epoch_loss / step}')\n",
    "\n",
    "# model.save_pretrained(model_dir)\n",
    "# tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Preprocess the test data\n",
    "encoded_test_data = tokenizer.batch_encode_plus(\n",
    "    test_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "test_labels = torch.tensor(test_data['score_norm'].values, dtype=torch.float32)\n",
    "test_dataset = TensorDataset(encoded_test_data['input_ids'], encoded_test_data['attention_mask'], test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model's predictions against the actual values\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.squeeze(1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "result_df = pd.DataFrame({'actual': actuals, 'predicted': predictions})\n",
    "\n",
    "form = pd.DataFrame(columns=['comment', 'actual', 'predicted'])\n",
    "count = 0\n",
    "for i in zip(test_data['comment'], result_df['actual'], result_df['predicted']):\n",
    "    form.loc[count] = [i[0], i[1], i[2]]\n",
    "    count += 1\n",
    "\n",
    "sorted_df = form.sort_values(by='predicted', ascending=False)\n",
    "\n",
    "for index, row in sorted_df.iterrows():\n",
    "    print(f\"comment: {row['comment']}\")\n",
    "    print(f\"actual: {row['actual']}\")\n",
    "    print(f\"predicted: {row['predicted']}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438e308",
   "metadata": {},
   "source": [
    "pythainlp/thainer-corpus-v2-base-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf75e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.024240271653980017\n",
      "Epoch: 2, Loss: 0.007770168886054307\n",
      "Epoch: 3, Loss: 0.0061607189127244055\n",
      "Mean Squared Error: 0.0665\n",
      "Mean Absolute Error: 0.2102\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§à¸§ à¸ªà¹ˆà¸‡à¸à¹ˆà¸­à¸™à¸à¸³à¸«à¸™à¸”4à¸§à¸±à¸™à¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸•à¸²à¸¡à¸›à¸ à¸£à¸²à¸„à¸²à¸”à¸µà¹„à¸¡à¹ˆà¹à¸žà¸‡ à¹€à¸„à¸¢à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§à¸Šà¸­à¸š à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸¥à¸´à¸›à¹€à¸›à¸·à¹‰à¸­à¸™à¹à¸¡à¸ªà¹„à¸”à¹‰à¸”à¸µ\n",
      "actual: 0.8888888955116272\n",
      "predicted: 1.137207269668579\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆ à¹„à¸”à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡ à¹à¸žà¹‡à¸„à¹€à¸à¸ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢à¹à¸•à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¥à¸à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸² à¸£à¸²à¸„à¸²à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹‚à¸”à¸¢à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡ à¹‚à¸­à¸à¸²à¸ªà¸«à¸™à¹‰à¸²à¸„à¹ˆà¸­à¸¢à¸‹à¸·à¹‰à¸­à¹€à¸žà¸´à¹ˆà¸¡à¸™à¸°à¸„à¸£à¸±à¸š\n",
      "actual: 0.8888888955116272\n",
      "predicted: 1.0993088483810425\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸„à¹ˆà¸° à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸¹à¸”à¸µ à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡ à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¹† à¸„à¸£à¸±à¹‰à¸‡à¸•à¹ˆà¸­à¹„à¸›à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸° à¸ªà¸²à¸¢à¸ªà¸§à¸¢à¹† à¸™à¹ˆà¸²à¸£à¸±à¸à¹†\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0682270526885986\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¸ à¸²à¸¢à¹ƒà¸™à¹„à¸¡à¹ˆà¸à¸µà¹ˆà¸§à¸±à¸™ à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸ªà¹ˆà¸‡à¸ˆà¸²à¸à¹ƒà¸™à¹„à¸—à¸¢à¹€à¸¥à¸¢ à¸žà¸±à¸ªà¸”à¸¸à¸à¸¥à¹ˆà¸­à¸‡ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸à¸°à¸‹à¸­à¸‡à¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸² à¹à¸•à¹ˆà¸„à¸²à¸”à¸§à¹ˆà¸²à¸™à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸›à¸à¸•à¸´ à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸­à¸°à¹„à¸£ à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆà¹à¸¥à¸°à¸ˆà¸°à¸à¸¥à¸±à¸šà¸¡à¸²à¸‹à¸·à¹‰à¸­à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 1.060790777206421\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆà¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0516772270202637\n",
      "\n",
      "comment: à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²: à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸”à¹‰à¸£à¸±à¸šà¹à¸¥à¹‰à¸§à¸ªà¹ˆà¸‡à¸¡à¸²à¸ˆà¸²à¸à¸•à¹ˆà¸²à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸‚à¸™à¸ªà¹ˆà¸‡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸—à¸°à¸™à¸¸à¸–à¸™à¸­à¸¡à¸”à¸µà¸¥à¸­à¸‡à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸”à¸µà¹‹à¸¢à¸§à¸‚à¸­à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸à¹ˆà¸­à¸™à¸™à¸°à¸„à¸°à¸§à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸µà¹à¸•à¹ˆà¸£à¸²à¸„à¸²à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 1.0504305362701416\n",
      "\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸‚à¸­à¸‡à¹„à¸”à¹‰à¸•à¸£à¸‡à¸£à¸¹à¸›à¸•à¸£à¸‡à¸›à¸à¸—à¸±à¹‰à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸—à¸±à¹‰à¸‡à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œ à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸²à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸šà¸²à¸‡à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹à¸•à¹ˆà¸à¹‡à¸ªà¸¡à¸à¸±à¸šà¸£à¸²à¸„à¸²à¸™à¸µà¹‰à¸„à¹ˆà¸° à¸¡à¸²à¸—à¸µà¹ˆà¹€à¸¡à¸²à¸ªà¹Œà¹à¸™à¸°à¸™à¸³à¸§à¹ˆà¸²à¹ƒà¸«à¹‰à¸«à¸²à¹à¸œà¹ˆà¸™à¸£à¸­à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸”à¹‰à¸§à¸¢à¸™à¸°à¸„à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸„à¸£à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ à¹€à¸žà¸£à¸²à¸°à¸–à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸±à¸šà¹‚à¸•à¹Šà¸°à¹€à¸›à¸¥à¹ˆà¸²à¹†à¹€à¸¥à¹€à¸‹à¸­à¸£à¹Œà¸ˆà¸°à¹„à¸›à¸•à¸´à¸”à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸£à¸²à¸„à¸²à¹à¸¥à¸°à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸„à¹ˆà¸°ðŸ˜Š\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0273195505142212\n",
      "\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸„à¹ˆà¸° à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸¹à¸à¸”à¸µ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸‡à¹ˆà¸²à¸¢à¸¡à¸²à¸ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸¥à¸·à¹ˆà¸™ à¹„à¸§à¸„à¹ˆà¸° à¸à¹‡à¸–à¸™à¸±à¸”à¸”à¸µ à¹„à¸§à¹‰à¸ˆà¸°à¸­à¸¸à¸”à¸«à¸™à¸¸à¸™à¹ƒà¸«à¸¡à¹ˆà¸™à¸°à¸„à¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 1.0255553722381592\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸‡à¸›à¸à¸„à¹ˆà¸° à¸¥à¸¹à¸à¸Šà¸­à¸šà¸¡à¸²à¸à¸„à¹ˆà¸°à¸¡à¸µà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œ à¸à¹‡à¸¡à¸µà¸ªà¸µà¸«à¸¥à¸²à¸¢à¸ªà¸µ à¹ƒà¸«à¹‰à¹€à¸¥à¸·à¸­à¸ à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œà¸‡à¹ˆà¸²à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 1.0227794647216797\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸¥à¸±à¸à¸©à¸“à¹Œà¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸•à¸²à¸¡à¸›à¸ à¹à¸•à¹ˆà¸•à¸±à¸§à¹€à¸£à¸·à¸­à¸™à¹ƒà¸«à¸à¹ˆà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ à¹à¸•à¹ˆà¸•à¸­à¸šà¹€à¹€à¸Šà¹‡à¸—à¸Šà¹‰à¸²à¸¡à¸²à¸ à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸­à¸¥à¸­à¸‡à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µà¸‚à¸™à¸²à¸”à¹„à¸«à¸™\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.9940800666809082\n",
      "\n",
      "comment: à¸¥à¸­à¸‡à¹à¸¥à¹‰à¸§à¹‚à¸­à¹€à¸„.à¹„à¸Ÿà¸•à¸´à¸”à¸—à¸¸à¸à¸”à¸§à¸‡.à¸£à¸µà¹‚à¸¡à¸—à¹ƒà¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹‚à¸­à¹€à¸„à¸¡à¸µà¸–à¹ˆà¸²à¸™à¸•à¸´à¸´à¸”à¸¡à¸²à¹à¸¥à¹‰à¸§à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹€à¸¥à¸¢..à¹„à¸Ÿà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¸‡à¸²à¸¡. à¹à¸žà¹‡à¸„à¸‚à¸­à¸‡à¸«à¹ˆà¸­à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢.à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸š. à¸•à¸£à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡à¸‹à¸·à¹‰à¸­. à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸µà¹‚à¸—à¸£à¹à¸ˆà¹‰à¸‡à¸à¹ˆà¸­à¸™à¹€à¸‚à¹‰à¸²à¸¡à¸²à¸ªà¹ˆà¸‡...\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.9939457774162292\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸ à¸²à¸žà¸£à¸§à¸¡à¹‚à¸­à¹€à¸„à¹€à¸¥à¸¢ à¹„à¸”à¹‰à¸¡à¸µà¸¡ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸­à¸­à¸ à¸šà¸£à¸´à¸«à¸²à¸£à¹‚à¸”à¸¢à¹€ à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9837831854820251\n",
      "\n",
      "comment: à¸”à¸µà¸„à¹ˆà¸° à¹à¸•à¹ˆà¹€à¸§à¸¥à¸²à¹‚à¸”à¸™à¸à¹‡à¸žà¸­à¸ªà¸‡à¹ˆà¸²à¸¢à¹€à¸à¸´à¸™à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¹‡à¹ƒà¸Šà¹‰à¸‡à¹ˆà¸²à¸¢ à¸žà¸à¸žà¸²à¸‡à¹ˆà¸²à¸¢à¸ªà¸°à¸”à¸§à¸à¸„à¹ˆà¸° à¹à¸šà¸•à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸­à¸¶à¸”à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹€à¸›à¸´à¸”à¸›à¸´à¸”à¸à¸²à¸à¹‡à¹„à¸¡à¹ˆà¸à¹Šà¸­à¸à¹à¸à¹Šà¸‡ à¸‚à¸™à¸ªà¹ˆà¸‡à¹„à¸§à¸„à¹ˆà¸°\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.9753789305686951\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸²à¸à¹† à¸à¸²à¸£à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸ˆà¸²à¸à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹† à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡âœ¨\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.972619354724884\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸›à¸à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¹†à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡à¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸œ à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹†à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢ à¸¡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9533067941665649\n",
      "\n",
      "comment: à¸•à¸°à¸¡à¸¸à¸•à¸°à¸¡à¸´à¸™à¹ˆà¸²à¸£à¸±à¸  à¹€à¸ªà¸µà¸¢à¸‡à¹à¸ˆà¹ˆà¸¡à¸”à¸µà¸„à¹ˆà¸°  à¸Šà¸­à¸šà¸¡à¸²à¸  à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.9497267007827759\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸‚à¸²à¸§ à¹à¸•à¹ˆà¸ªà¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¸¡à¸²à¹à¸—à¸™ à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸–à¸²à¸¡à¸à¹ˆà¸­à¸™ à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸±à¸™à¸ªà¸¡à¸±à¸¢ à¸ˆà¸±à¸šà¸–à¸™à¸±à¸”à¸¡à¸·à¸­\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.9208805561065674\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸—à¸£à¸‡à¹€à¸—à¹ˆà¸”à¸µ à¸§à¸±à¸ªà¸”à¸¸à¸”à¸µ à¸šà¸²à¸‡à¸„à¸£à¸±à¹‰à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¢à¸±à¸‡à¸«à¸™à¹ˆà¸§à¸‡à¸šà¹‰à¸²à¸‡à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢ à¹à¸•à¹ˆà¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸ªà¸¡à¸£à¸²à¸„à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.9139390587806702\n",
      "\n",
      "comment: à¹‚à¸­à¹€à¸„à¸™à¸°à¸„à¸°à¸à¹‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸Šà¸²à¸£à¹Œà¸ˆà¸à¸±à¸š Apple Watch à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹‚à¸­à¹€à¸„à¸­à¸¢à¸¹à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸§à¸£à¹‰à¸²à¸¢à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹€à¸£à¸·à¹ˆà¸­à¸‡à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹à¸žà¸‡à¹à¸•à¹ˆà¸‚à¹‰à¸­à¸”à¸µà¸à¹‡à¸„à¸·à¸­à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸žà¸£à¸µà¸­à¸­à¹€à¸”à¸­à¸£à¹Œà¸¡à¸µà¸‚à¸­à¸‡à¸žà¸£à¹‰à¸­à¸¡à¸ªà¹ˆà¸‡à¹€à¸¥à¸¢à¸™à¸µà¹ˆà¸„à¸·à¸­à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸•à¸±à¸§à¸™à¸µà¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸à¹‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸­à¸²à¸ˆà¸ˆà¸°à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸à¹‰à¸­à¸‡à¹à¸à¹Šà¸‡à¸„à¹Œà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸ˆà¸±à¸”à¹€à¸•à¹‡à¸¡à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8712459206581116\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¢à¸´à¸™à¸™à¸´à¸”à¸™à¸¶à¸‡à¹à¸•à¹ˆà¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¹‰à¸²à¸™à¹ƒà¸™à¸¢à¸±à¸‡à¹‚à¸­à¹€à¸„ à¹€à¸”à¸µà¹‹à¸¢à¸§à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸›à¸à¸•à¸´à¸¡à¸±à¹Šà¸¢\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.8652111887931824\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸›à¸ªà¸µà¸¡à¹ˆà¸§à¸‡ à¹à¸•à¹ˆà¸ªà¸µà¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸­à¸­à¸à¹€à¸›à¹‡à¸™à¸ªà¸µà¸Ÿà¹‰à¸² à¹„à¸¡à¹ˆà¸–à¸¹à¸à¹ƒà¸ˆà¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µ à¹à¸•à¹ˆà¸„à¸µà¸¢à¹Œà¸šà¸­à¸£à¹Œà¸”à¸ªà¸¥à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¸›à¸¸à¹ˆà¸¡à¹„à¸«à¸™ à¸”à¸¹à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹à¸ˆà¹‰à¸‡ à¹à¸•à¹ˆà¸à¸”à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¹ˆà¸°  à¸‡à¸‡à¸¡à¸²à¸ à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¹€à¸£à¹‡à¸§à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8610354065895081\n",
      "\n",
      "comment: à¸•à¸´à¸”à¹†à¸«à¸¥à¸¸à¸”à¹†à¸‡à¸‡à¹† à¸Šà¸²à¸£à¹Œà¸ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡ à¹€à¸£à¸²à¹ƒà¸Šà¹‰à¹„à¸­à¹‚à¸Ÿà¸™11 à¸™à¸­à¸¢ à¸•à¸­à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆà¹€à¸žà¸£à¸²à¸°2à¹€à¸¡à¸•à¸£à¸£à¸¶à¸›à¹ˆà¸²à¸§ à¸–à¹‰à¸²1à¹€à¸¡à¸•à¸£à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² à¹à¸žà¹‡à¸„à¸”à¸µ à¸ªà¹ˆà¸‡à¹„à¸§\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8442419171333313\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹€à¸²à¸”à¸µà¸„à¹ˆà¸° à¸•à¸£à¸‡à¸›à¸ à¸ªà¹ˆà¸‡à¹„à¸§ à¹à¸•à¹ˆà¸«à¸±à¸1à¸”à¸²à¸§à¹€à¸žà¸£à¸²à¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Ÿà¹‰à¸²à¹„à¸›à¹à¸™à¹ˆà¸§à¹ˆà¸ªà¹„à¸”à¹‰à¸ªà¸£à¸‚à¸²à¸§à¸¡à¸²à¹à¸—à¸™ à¹à¸•à¹ˆà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸„à¹ˆà¸° à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¹†à¸”à¹‰à¸›à¸à¸•à¸´à¹€à¸¥à¸¢ à¹‚à¸­à¹€à¸„à¸¡à¸²à¸\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.841704249382019\n",
      "\n",
      "comment: à¸ªà¸§à¸¢à¸”à¸µà¸„à¹ˆà¸°à¹à¸•à¹ˆà¹à¸šà¸•à¸«à¸¡à¸”à¹„à¸§à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹€à¸¥à¹ˆà¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸›à¹‡à¸™à¸”à¹‰à¸§à¸¢à¸‡à¸‡à¹†à¸™à¸´à¸ªà¸™à¸¶à¸‡à¹ƒà¸ªà¹ˆà¹à¸¥à¹‰à¸§à¸§à¸±à¸”à¹„à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸«à¸£à¸·à¸­à¹€à¸£à¸²à¸‡à¸‡à¹†à¹„à¸›à¹€à¸­à¸‡à¸à¹‰à¸­à¹„à¸¡à¹ˆà¸£à¸¸à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹à¸à¹ˆà¸£à¸²à¸„à¸²à¸„à¹ˆà¸°à¸¥à¸¹à¸à¸­à¸¢à¸²à¸à¹„à¸”à¹‰à¸à¹‰à¸­à¹€à¸¥à¸¢à¸ˆà¸±à¸”à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸”à¸¹à¸ªà¸±à¸à¸žà¸±à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸—à¸™à¸—à¸²à¸™à¸¡à¸±à¹‰à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8335413932800293\n",
      "\n",
      "comment: à¸Šà¸­à¸šà¸¡à¸²à¸à¹€à¸¥à¸¢à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸­à¸¢à¸ªà¸µà¹€à¸­à¹ˆà¸¢à¸”à¸µà¹„à¸›à¸«à¸¡à¸”à¸”à¸¹à¹€à¸£à¸µà¸¢à¸šà¹à¸•à¹ˆà¸ªà¸§à¸¢à¸ªà¸µà¸”à¸³à¸ªà¸§à¸¢à¸¡à¸²à¸à¸ªà¸µà¹€à¸—à¸²à¸à¹‡à¸ªà¸§à¸¢à¹„à¸§à¹‰à¸ˆà¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¹€à¸—à¸²à¸­à¸µà¸à¸„à¹ˆà¸°à¸—à¸£à¸‡à¸ªà¸§à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¹€à¸ˆà¹‡à¸šà¸«à¸¹\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8080272078514099\n",
      "\n",
      "comment: à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸”à¸”à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¸²à¸„à¸²à¹„à¸¡à¸²à¹€à¸à¸´à¸™à¸£à¹‰à¸­à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸à¸³à¸¥à¸±à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸±à¸‡à¹„à¸›à¹„à¸¡à¹ˆà¹€à¸šà¸²à¹„à¸› à¹à¸•à¹ˆà¹€à¸šà¸ªà¸à¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸à¸£à¸µà¸¢à¸”à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8031903505325317\n",
      "\n",
      "comment: à¹à¸žà¹Šà¸„à¸‚à¸­à¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸ à¸à¸¥à¹ˆà¸­à¸‡à¸ªà¸²à¸¢à¸šà¸¸à¸šà¹„à¸›à¹€à¸à¸·à¸­à¸šà¸„à¸£à¸¶à¹ˆà¸‡ à¸ªà¸±à¹ˆà¸‡à¸„à¸£à¸±à¹‰à¸‡à¸™à¸µà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¸ˆà¸°à¹„à¸¡à¹ˆà¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸¥à¹‰à¸§\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7903041243553162\n",
      "\n",
      "comment: à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸¡à¸²à¸ªà¸±à¸à¸žà¸±à¸à¸”à¸µà¸¡à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¹ˆà¹à¸•à¸à¹€à¸šà¸ªà¸«à¸™à¸±à¸à¸Ÿà¸±à¸‡à¹€à¸žà¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¸¡à¸²à¸à¸¡à¸µà¸•à¸³à¸«à¸™à¸´à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¸‚à¸­à¸šà¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£à¹à¸šà¸•à¸—à¸™à¸¡à¸²à¸à¸Šà¸²à¸£à¹Œà¸ˆ1à¸„à¸£à¸±à¹‰à¸‡à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¹„à¸”à¹‰à¸¡à¸²à¸§à¸±à¸™à¹à¸£à¸à¸ˆà¸™à¸–à¸¶à¸‡à¸§à¸±à¸™à¸™à¸µà¹‰à¹à¸šà¸•à¸¢à¸±à¸‡à¹€à¸«à¸¥à¸·à¸­à¸­à¸µà¸50à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7900210022926331\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸•à¸²à¸¡à¸£à¸²à¸„à¸² à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¸§ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.788259744644165\n",
      "\n",
      "comment: à¸à¹ˆà¸­à¸™à¸‹à¸·à¹‰à¸­à¸à¹‡à¸­à¸¸à¸•à¸ªà¹ˆà¸²à¸«à¹Œà¸”à¸¹à¹ƒà¸™à¸£à¸µà¸§à¸´à¸§à¹à¸¥à¹‰à¸§à¸™à¸° à¸à¹‡à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸›à¸¸à¹ˆà¸¡à¹„à¸—à¸¢à¹à¸—à¹‰ à¹à¸•à¹ˆà¸žà¸­à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸à¹‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸¡à¸²à¸ à¹€à¸›à¹‡à¸™à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹„à¸—à¸¢à¸‹à¸°à¸‡à¸±à¹‰à¸™ à¸‹à¸¶à¹ˆà¸‡à¸žà¸­à¸•à¸´à¸”à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹à¸¥à¹‰à¸§ à¸¡à¸±à¸™à¸¡à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸¥à¸²à¸‡à¸„à¸·à¸™ à¸¥à¸³à¸šà¸²à¸à¹à¸¥à¸°à¸«à¸‡à¸¸à¸”à¸«à¸‡à¸´à¸”à¸¡à¸²à¸ à¸‹à¸·à¹‰à¸­à¹à¸šà¸šà¸¡à¸µà¹„à¸Ÿ à¹à¸•à¹ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿ à¸Šà¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸—à¸µà¹ˆà¹„à¸£à¹‰à¸„à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸ˆà¸£à¸´à¸‡ à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸ˆà¸£à¸´à¸‡à¹† à¸£à¸¹à¹‰à¸‡à¸µà¹‰ à¸‹à¸·à¹‰à¸­à¸£à¹‰à¸²à¸™à¸­à¸·à¹ˆà¸™ à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¹à¸›à¹‰à¸™à¹„à¸—à¸¢à¹à¸—à¹‰à¸”à¸µà¸à¸§à¹ˆà¸²\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.788014829158783\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸§à¸±à¸™à¹€à¸”à¸µà¸¢à¸§à¸–à¸¶à¸‡à¸«à¸±à¸1à¸„à¸°à¹à¸™à¸™ à¹€à¸žà¸£à¸²à¸°à¹„à¸¡à¹ˆà¸«à¹‰à¸­à¸à¸±à¸™à¸›à¸£à¸°à¹à¸—à¸ à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸„à¸¸à¹‰à¸¡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7722446918487549\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¸¥à¸³à¹‚à¸žà¸‡à¹€à¸¥à¸°à¹€à¸—à¸°à¸¡à¸²à¸à¸•à¸±à¹‰à¸‡à¹€à¹€à¸•à¹ˆà¹€à¹€à¸à¸° à¸•à¹‰à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¸¥à¸³à¹‚à¸žà¸‡à¸•à¸¥à¸­à¸”à¹€à¸§à¸¥à¸²à¸–à¸¶à¸‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸«à¸¥à¸¸à¸”à¸šà¹ˆà¸­à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7691552042961121\n",
      "\n",
      "comment: à¹ƒà¸«à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸‹à¹‰à¸³à¹à¸¥à¸°à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸„à¸£à¸š à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸ˆà¸±à¸”à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7670843005180359\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸‚à¸­à¸‡à¸¡à¸²à¸§à¸±à¸™à¸—à¸µà¹ˆ13 à¸§à¸±à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸™à¸„à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§à¸à¹‡à¸”à¸±à¸šà¹„à¸›à¹€à¸¥à¸¢ à¹€à¸›à¸´à¸”à¹„à¸¡à¹ˆà¸•à¸´à¸”à¸­à¸µà¸à¹€à¸¥à¸¢ à¸¥à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¹à¸¥à¹‰à¸§à¸à¹‡à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.761914074420929\n",
      "\n",
      "comment: à¸—à¸±à¸à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸•à¸­à¸š à¹ƒà¸™à¸£à¸¹à¸›à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸ªà¸²à¸¢à¹à¸ˆà¹Šà¸ª à¸‚à¸­à¸‡à¸¡à¸²à¸–à¸¶à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸”à¸¹à¹à¸¥\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.7431032657623291\n",
      "\n",
      "comment: à¸§à¸±à¸ªà¸”à¸¸à¸à¹Šà¸­à¸‡à¹à¸à¹Šà¸‡à¸¡à¸²à¸ à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¹„à¸”à¹‰à¸ªà¸µà¸Ÿà¹‰à¸²\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.7408309578895569\n",
      "\n",
      "comment: à¸›à¸¸à¹ˆà¸¡à¸à¸”à¸”à¹‰à¸²à¸™à¸‹à¹‰à¸²à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸•à¸´à¸”à¹†à¸­à¸°à¹„à¸£à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸¥à¸‡ à¹€à¸¥à¸·à¹ˆà¸­à¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹„à¸› à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸•à¸´à¸”à¸›à¸à¸•à¸´à¹à¸•à¹ˆà¹„à¸§à¹„à¸Ÿà¸¢à¸±à¸‡à¸•à¹ˆà¸­à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸¢ à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹€à¸‡à¸´à¸™\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7373223900794983\n",
      "\n",
      "comment: à¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸–à¸­à¸”à¹€à¸‚à¹‰à¸²à¸–à¸­à¸”à¸­à¸­à¸à¸¢à¸²à¸ à¹‚à¸—à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸ªà¸–à¸µà¸¢à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7372894287109375\n",
      "\n",
      "comment: à¸œà¸¡à¹ƒà¸Šà¹‰iPhone14 Pro Max 512, à¸¡à¸µà¹€à¸„à¸ªà¸‚à¸­à¸‡casetify. à¹à¸¡à¹ˆà¹€à¸«à¸¥à¹‡à¸à¸ˆà¸±à¸šà¸”à¸µà¸„à¸£à¸±à¸š à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸µà¸¡à¸²à¸ à¹à¸•à¹ˆ!!! à¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡ à¸–à¸­à¸”à¹€à¸„à¸ªà¸¡à¸²à¸Šà¸²à¸£à¹Œà¸ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¸¡à¸²à¸¢à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¸–à¸·à¸­à¸ªà¸°à¸§à¹ˆà¸²à¹€à¸­à¸²à¸¡à¸²à¸§à¸²à¸‡à¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œà¹€à¸‰à¸¢à¹† à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸²à¸„à¸¸à¸“à¸¡à¸µà¹€à¸„à¸ªà¸«à¸™à¸² 1à¸”à¸²à¸§à¹ƒà¸«à¹‰à¸à¸²à¸£à¸šà¸”à¸µà¹„à¸‹à¸™à¹Œ à¸™à¸­à¸à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸”à¸²à¸§à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 0.7327829003334045\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§ à¸Šà¸³à¸£à¸¸à¸”à¸„à¹ˆà¸° à¹à¸•à¸ à¸™à¹ˆà¸²à¸ˆà¸°à¸«à¹ˆà¸­à¹„à¸¡à¹ˆà¸”à¸µà¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸«à¹ˆà¸­à¸­à¸°à¹„à¸£à¹€à¸¥à¸¢ à¹ƒà¸ªà¹ˆà¹à¸„à¹ˆà¸–à¸¸à¸‡à¸¡à¸² à¹à¸šà¸šà¸™à¸µà¹‰à¸‚à¸­à¸‡à¸à¹‰à¸­à¸žà¸±à¸‡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸«à¸¡à¸”à¸ªà¸´à¸„à¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7295905947685242\n",
      "\n",
      "comment: à¸ªà¸±à¸‡à¹€à¸à¸•à¸”à¸µà¹†à¸¡à¸µà¸£à¸­à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸–à¸¹à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§à¸”à¹‰à¸§à¸¢ à¸¡à¸±à¸™à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¹à¸¢à¹ˆà¹à¸¥à¸°à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸™à¹ˆà¸°à¸„à¹ˆà¸° à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹à¸£à¸à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸ˆà¸°à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹„à¸”à¹‰à¸£à¸¶à¹€à¸›à¸¥à¹ˆà¸²ðŸ¥²ðŸ˜­\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.6940886378288269\n",
      "\n",
      "comment: à¸Šà¸²à¸£à¹Œà¸ˆà¸Šà¹‰à¸²à¸¡à¸²à¸à¸„à¹ˆà¸° à¸Šà¸²à¸£à¹Œà¸ˆà¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸™à¸­à¸™ à¸•à¸·à¹ˆà¸™à¸¡à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸•à¹‡à¸¡à¹€à¸¥à¸¢\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6896546483039856\n",
      "\n",
      "comment: à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸” à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¸„à¹Œà¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸žà¸¥à¸‡à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6528456807136536\n",
      "\n",
      "comment: à¹ƒà¸ªà¹ˆà¸‹à¸´à¸¡à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸±à¸à¸à¸²à¸“ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸¥à¸‡à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸•à¸­à¸šà¸Šà¹‰à¸²\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.6270714402198792\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸Šà¹‰à¸²à¸¡à¸² à¸£à¸­à¸¡à¸²à¸„à¸£à¸¶à¹ˆà¸‡à¹€à¸”à¸·à¸­à¸™à¸žà¸¶à¹ˆà¸‡à¸ˆà¸°à¹„à¸”à¹‰ à¸–à¹‰à¸²à¹ƒà¸„à¸£à¸£à¸µà¸šà¹„à¸›à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.6268399953842163\n",
      "\n",
      "comment: à¹à¸¢à¹ˆ à¸£à¹‰à¸­à¸™à¸¡à¸²à¸à¹€à¸§à¸¥à¸²à¸Šà¸²à¸£à¹Œà¸ˆ à¸¡à¸µtype-c à¹à¸•à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸­à¸­à¸à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸¡à¸µà¹„à¸§à¹‰à¹€à¸žà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.584926187992096\n",
      "\n",
      "comment: à¸‚à¸­à¸‡à¸žà¸¶à¹ˆà¸‡à¹„à¸”à¹‰à¸¡à¸²à¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™à¹ƒà¸Šà¹‰à¸•à¸­à¸™à¹€à¸Šà¹‰à¸²à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸œà¸¡à¸£à¸­à¸‚à¸­à¸‡à¸•à¸±à¹‰à¸‡à¸™à¸²à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¸‚à¸§à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.579571008682251\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸„à¸²à¸”à¸«à¸§à¸±à¸‡ à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹à¸¢à¹ˆà¸¡à¸²à¸\n",
      "actual: 0.0\n",
      "predicted: 0.5787436366081238\n",
      "\n",
      "comment: à¸«à¸¹à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¸¢à¸´à¸™à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¹„à¸¡à¹ˆà¸”à¸µà¹€à¸¥à¸¢ à¸à¸²à¸£à¹à¸žà¸„à¸à¸¥à¹ˆà¸­à¸‡à¸à¹‡à¹„à¸¡à¹ˆà¸ªà¸¡à¸›à¸£à¸°à¸à¸­à¸š à¸‚à¸²à¸”\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.5738264322280884\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µà¹€à¸à¸´à¸™à¸£à¸²à¸„à¸² à¸•à¹‰à¸­à¸‡à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.5498558878898621\n",
      "\n",
      "comment: à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸£à¸²à¸„à¸²\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.5080092549324036\n",
      "\n",
      "comment: à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸„à¸™à¸¥à¸°à¸£à¸¸à¹ˆà¸™à¸à¸±à¸™à¸Šà¸²à¸ˆà¹„à¸¡à¹ˆà¹ƒà¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.47299259901046753\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸”à¸³à¹„à¸”à¹‰à¸ªà¸µà¸™à¹‰à¸³à¹€à¸‡à¸´à¸™ à¸šà¸­à¸à¸žà¸™à¸±à¸à¸‡à¸²à¸™à¸ªà¹ˆà¸‡à¸œà¸´à¸” à¹à¸•à¹ˆà¸”à¸¹à¸ˆà¸²à¸à¸£à¸µà¸§à¸´à¸§à¸ªà¹ˆà¸‡à¸œà¸´à¸”à¸šà¹ˆà¸­à¸¢à¹„à¸›à¸™à¸°à¸„à¸°...\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.4678758978843689\n",
      "\n",
      "comment: à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸šà¸²â€‹\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.4313405752182007\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹„à¸¡à¹ˆà¹„à¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.3831729292869568\n",
      "\n",
      "comment: à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.34193840622901917\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¹€à¸¥à¸¢\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.34062060713768005\n",
      "\n",
      "comment: à¸”à¸µà¸¡à¸²à¸à¹†\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.32711607217788696\n",
      "\n",
      "comment: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸„à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.29417163133621216\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸‹à¸·à¹‰à¸­\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.007425684481859207\n",
      "\n",
      "comment: à¸‚à¸™à¸ªà¹ˆà¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: -0.08076976239681244\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸²à¸¢à¸Šà¸²à¸£à¹Œà¸•à¸ªà¹ˆà¸‡à¸¡à¸²à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: -0.09394565224647522\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž\n",
      "actual: 0.2222222238779068\n",
      "predicted: -0.09415403753519058\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸«à¸¹à¸Ÿà¸±à¸‡à¸¡à¸²à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§\n",
      "actual: 0.4444444477558136\n",
      "predicted: -0.10156594961881638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model2\n",
    "tokenizer = tokenizer2\n",
    "\n",
    "# Define your loss function\n",
    "loss_fn = torch.nn.MSELoss()  # Change loss function to L1Loss for regression\n",
    "\n",
    "# Move your model to the device (CPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Set up gradient accumulation\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Define batch and epochs\n",
    "batch_size = 16  # Reduced batch size\n",
    "num_epochs = 3\n",
    "\n",
    "# Tokenize data and create dataloader\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    train_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=200,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "labels = torch.tensor(train_data['score_norm'].values, dtype=torch.float32)  # Convert labels to float32\n",
    "dataset = TensorDataset(encoded_data['input_ids'], encoded_data['attention_mask'], labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Fine-tune the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        step += 1\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {epoch_loss / step}')\n",
    "\n",
    "# model.save_pretrained(model_dir)\n",
    "# tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Preprocess the test data\n",
    "encoded_test_data = tokenizer.batch_encode_plus(\n",
    "    test_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "test_labels = torch.tensor(test_data['score_norm'].values, dtype=torch.float32)\n",
    "test_dataset = TensorDataset(encoded_test_data['input_ids'], encoded_test_data['attention_mask'], test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model's predictions against the actual values\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.squeeze(1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "result_df = pd.DataFrame({'actual': actuals, 'predicted': predictions})\n",
    "\n",
    "form = pd.DataFrame(columns=['comment', 'actual', 'predicted'])\n",
    "count = 0\n",
    "for i in zip(test_data['comment'], result_df['actual'], result_df['predicted']):\n",
    "    form.loc[count] = [i[0], i[1], i[2]]\n",
    "    count += 1\n",
    "\n",
    "sorted_df = form.sort_values(by='predicted', ascending=False)\n",
    "\n",
    "for index, row in sorted_df.iterrows():\n",
    "    print(f\"comment: {row['comment']}\")\n",
    "    print(f\"actual: {row['actual']}\")\n",
    "    print(f\"predicted: {row['predicted']}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921cf60",
   "metadata": {},
   "source": [
    "KoichiYasuoka/roberta-base-thai-spm-upos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2804cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.02072158391820267\n",
      "Epoch: 2, Loss: 0.0054933749488554895\n",
      "Epoch: 3, Loss: 0.00597289192955941\n",
      "Mean Squared Error: 0.0318\n",
      "Mean Absolute Error: 0.1460\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸‚à¸­à¸‡à¹„à¸”à¹‰à¸•à¸£à¸‡à¸£à¸¹à¸›à¸•à¸£à¸‡à¸›à¸à¸—à¸±à¹‰à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸—à¸±à¹‰à¸‡à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œ à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸§à¹ˆà¸²à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸šà¸²à¸‡à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹à¸•à¹ˆà¸à¹‡à¸ªà¸¡à¸à¸±à¸šà¸£à¸²à¸„à¸²à¸™à¸µà¹‰à¸„à¹ˆà¸° à¸¡à¸²à¸—à¸µà¹ˆà¹€à¸¡à¸²à¸ªà¹Œà¹à¸™à¸°à¸™à¸³à¸§à¹ˆà¸²à¹ƒà¸«à¹‰à¸«à¸²à¹à¸œà¹ˆà¸™à¸£à¸­à¸‡à¹€à¸¡à¸²à¸ªà¹Œà¸”à¹‰à¸§à¸¢à¸™à¸°à¸„à¸°à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸„à¸£à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ à¹€à¸žà¸£à¸²à¸°à¸–à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸±à¸šà¹‚à¸•à¹Šà¸°à¹€à¸›à¸¥à¹ˆà¸²à¹†à¹€à¸¥à¹€à¸‹à¸­à¸£à¹Œà¸ˆà¸°à¹„à¸›à¸•à¸´à¸”à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸—à¸±à¹‰à¸‡à¸£à¸²à¸„à¸²à¹à¸¥à¸°à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸²à¸à¸²à¸£à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸„à¹ˆà¸°ðŸ˜Š\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8775432705879211\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸‡à¸›à¸à¸„à¹ˆà¸° à¸¥à¸¹à¸à¸Šà¸­à¸šà¸¡à¸²à¸à¸„à¹ˆà¸°à¸¡à¸µà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œ à¸à¹‡à¸¡à¸µà¸ªà¸µà¸«à¸¥à¸²à¸¢à¸ªà¸µ à¹ƒà¸«à¹‰à¹€à¸¥à¸·à¸­à¸ à¹€à¸§à¸¥à¸²à¸žà¸´à¸¡à¸žà¹Œà¸‡à¹ˆà¸²à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¹à¸›à¹‰à¸™à¸žà¸´à¸¡à¸žà¹Œà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8536656498908997\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆà¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸¡à¸²à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸”à¸µà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8508191108703613\n",
      "\n",
      "comment: à¸Šà¸­à¸šà¸¡à¸²à¸à¹€à¸¥à¸¢à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸­à¸¢à¸ªà¸µà¹€à¸­à¹ˆà¸¢à¸”à¸µà¹„à¸›à¸«à¸¡à¸”à¸”à¸¹à¹€à¸£à¸µà¸¢à¸šà¹à¸•à¹ˆà¸ªà¸§à¸¢à¸ªà¸µà¸”à¸³à¸ªà¸§à¸¢à¸¡à¸²à¸à¸ªà¸µà¹€à¸—à¸²à¸à¹‡à¸ªà¸§à¸¢à¹„à¸§à¹‰à¸ˆà¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¹€à¸—à¸²à¸­à¸µà¸à¸„à¹ˆà¸°à¸—à¸£à¸‡à¸ªà¸§à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¹€à¸ˆà¹‡à¸šà¸«à¸¹\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8459343910217285\n",
      "\n",
      "comment: à¸à¹ˆà¸­à¸™à¸‹à¸·à¹‰à¸­à¸à¹‡à¸­à¸¸à¸•à¸ªà¹ˆà¸²à¸«à¹Œà¸”à¸¹à¹ƒà¸™à¸£à¸µà¸§à¸´à¸§à¹à¸¥à¹‰à¸§à¸™à¸° à¸à¹‡à¹€à¸«à¹‡à¸™à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸›à¸¸à¹ˆà¸¡à¹„à¸—à¸¢à¹à¸—à¹‰ à¹à¸•à¹ˆà¸žà¸­à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸à¹‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸¡à¸²à¸ à¹€à¸›à¹‡à¸™à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹„à¸—à¸¢à¸‹à¸°à¸‡à¸±à¹‰à¸™ à¸‹à¸¶à¹ˆà¸‡à¸žà¸­à¸•à¸´à¸”à¸ªà¸•à¸´à¹Šà¸à¹€à¸à¸­à¸£à¹Œà¹à¸¥à¹‰à¸§ à¸¡à¸±à¸™à¸¡à¸­à¸‡à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸à¸¥à¸²à¸‡à¸„à¸·à¸™ à¸¥à¸³à¸šà¸²à¸à¹à¸¥à¸°à¸«à¸‡à¸¸à¸”à¸«à¸‡à¸´à¸”à¸¡à¸²à¸ à¸‹à¸·à¹‰à¸­à¹à¸šà¸šà¸¡à¸µà¹„à¸Ÿ à¹à¸•à¹ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿ à¸Šà¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¹„à¸Ÿà¸—à¸µà¹ˆà¹„à¸£à¹‰à¸„à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸ˆà¸£à¸´à¸‡ à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸ˆà¸£à¸´à¸‡à¹† à¸£à¸¹à¹‰à¸‡à¸µà¹‰ à¸‹à¸·à¹‰à¸­à¸£à¹‰à¸²à¸™à¸­à¸·à¹ˆà¸™ à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¹à¸›à¹‰à¸™à¹„à¸—à¸¢à¹à¸—à¹‰à¸”à¸µà¸à¸§à¹ˆà¸²\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.8443609476089478\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸„à¹ˆà¸° à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸¹à¸”à¸µ à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡ à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸¡à¸²à¸à¹† à¸„à¸£à¸±à¹‰à¸‡à¸•à¹ˆà¸­à¹„à¸›à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸° à¸ªà¸²à¸¢à¸ªà¸§à¸¢à¹† à¸™à¹ˆà¸²à¸£à¸±à¸à¹†\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8371546864509583\n",
      "\n",
      "comment: à¸œà¸¡à¹ƒà¸Šà¹‰iPhone14 Pro Max 512, à¸¡à¸µà¹€à¸„à¸ªà¸‚à¸­à¸‡casetify. à¹à¸¡à¹ˆà¹€à¸«à¸¥à¹‡à¸à¸ˆà¸±à¸šà¸”à¸µà¸„à¸£à¸±à¸š à¸”à¸µà¹„à¸‹à¸™à¹Œà¹€à¸µà¸¡à¸²à¸ à¹à¸•à¹ˆ!!! à¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸šà¹‰à¸²à¸‡ à¸–à¸­à¸”à¹€à¸„à¸ªà¸¡à¸²à¸Šà¸²à¸£à¹Œà¸ˆà¸à¹‡à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡ à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¸¡à¸²à¸¢à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¸–à¸·à¸­à¸ªà¸°à¸§à¹ˆà¸²à¹€à¸­à¸²à¸¡à¸²à¸§à¸²à¸‡à¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œà¹€à¸‰à¸¢à¹† à¹„à¸¡à¹ˆà¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸‹à¸·à¹‰à¸­à¸–à¹‰à¸²à¸„à¸¸à¸“à¸¡à¸µà¹€à¸„à¸ªà¸«à¸™à¸² 1à¸”à¸²à¸§à¹ƒà¸«à¹‰à¸à¸²à¸£à¸šà¸”à¸µà¹„à¸‹à¸™à¹Œ à¸™à¸­à¸à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸”à¸²à¸§à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 0.8342875838279724\n",
      "\n",
      "comment: à¸–à¸·à¸­à¸§à¹ˆà¸²à¸”à¸µà¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸”à¸”à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¸²à¸„à¸²à¹„à¸¡à¸²à¹€à¸à¸´à¸™à¸£à¹‰à¸­à¸¢à¹€à¸ªà¸µà¸¢à¸‡à¸à¸³à¸¥à¸±à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸±à¸‡à¹„à¸›à¹„à¸¡à¹ˆà¹€à¸šà¸²à¹„à¸› à¹à¸•à¹ˆà¹€à¸šà¸ªà¸à¸±à¸šà¹€à¸ªà¸µà¸¢à¸‡à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸à¸£à¸µà¸¢à¸”à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8218470811843872\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§à¸§ à¸ªà¹ˆà¸‡à¸à¹ˆà¸­à¸™à¸à¸³à¸«à¸™à¸”4à¸§à¸±à¸™à¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸•à¸²à¸¡à¸›à¸ à¸£à¸²à¸„à¸²à¸”à¸µà¹„à¸¡à¹ˆà¹à¸žà¸‡ à¹€à¸„à¸¢à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§à¸Šà¸­à¸š à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸¥à¸´à¸›à¹€à¸›à¸·à¹‰à¸­à¸™à¹à¸¡à¸ªà¹„à¸”à¹‰à¸”à¸µ\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.8214674592018127\n",
      "\n",
      "comment: à¹‚à¸­à¹€à¸„à¸™à¸°à¸„à¸°à¸à¹‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸Šà¸²à¸£à¹Œà¸ˆà¸à¸±à¸š Apple Watch à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹‚à¸­à¹€à¸„à¸­à¸¢à¸¹à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸§à¸£à¹‰à¸²à¸¢à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹€à¸£à¸·à¹ˆà¸­à¸‡à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¹à¸žà¸‡à¹à¸•à¹ˆà¸‚à¹‰à¸­à¸”à¸µà¸à¹‡à¸„à¸·à¸­à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸žà¸£à¸µà¸­à¸­à¹€à¸”à¸­à¸£à¹Œà¸¡à¸µà¸‚à¸­à¸‡à¸žà¸£à¹‰à¸­à¸¡à¸ªà¹ˆà¸‡à¹€à¸¥à¸¢à¸™à¸µà¹ˆà¸„à¸·à¸­à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡à¸•à¸±à¸§à¸™à¸µà¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸à¹‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸™à¸°à¸„à¸°à¹à¸•à¹ˆà¸­à¸²à¸ˆà¸ˆà¸°à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸à¹‰à¸­à¸‡à¹à¸à¹Šà¸‡à¸„à¹Œà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸ˆà¸±à¸”à¹€à¸•à¹‡à¸¡à¹à¸™à¹ˆà¸™à¸­à¸™à¸„à¹ˆà¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8194575905799866\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸›à¸ªà¸µà¸¡à¹ˆà¸§à¸‡ à¹à¸•à¹ˆà¸ªà¸µà¸ˆà¸£à¸´à¸‡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸­à¸­à¸à¹€à¸›à¹‡à¸™à¸ªà¸µà¸Ÿà¹‰à¸² à¹„à¸¡à¹ˆà¸–à¸¹à¸à¹ƒà¸ˆà¹€à¸¥à¸¢ à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µ à¹à¸•à¹ˆà¸„à¸µà¸¢à¹Œà¸šà¸­à¸£à¹Œà¸”à¸ªà¸¥à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¸›à¸¸à¹ˆà¸¡à¹„à¸«à¸™ à¸”à¸¹à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹à¸ˆà¹‰à¸‡ à¹à¸•à¹ˆà¸à¸”à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¹ˆà¸°  à¸‡à¸‡à¸¡à¸²à¸ à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¹€à¸£à¹‡à¸§à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8193668723106384\n",
      "\n",
      "comment: à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²: à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸”à¹‰à¸£à¸±à¸šà¹à¸¥à¹‰à¸§à¸ªà¹ˆà¸‡à¸¡à¸²à¸ˆà¸²à¸à¸•à¹ˆà¸²à¸‡à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸‚à¸™à¸ªà¹ˆà¸‡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸—à¸°à¸™à¸¸à¸–à¸™à¸­à¸¡à¸”à¸µà¸¥à¸­à¸‡à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸”à¸µà¹‹à¸¢à¸§à¸‚à¸­à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸à¹ˆà¸­à¸™à¸™à¸°à¸„à¸°à¸§à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹„à¸¡à¹ˆà¸”à¸µà¹à¸•à¹ˆà¸£à¸²à¸„à¸²à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8143784999847412\n",
      "\n",
      "comment: à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸¡à¸²à¸ªà¸±à¸à¸žà¸±à¸à¸”à¸µà¸¡à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¹ˆà¹à¸•à¸à¹€à¸šà¸ªà¸«à¸™à¸±à¸à¸Ÿà¸±à¸‡à¹€à¸žà¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¸¡à¸²à¸à¸¡à¸µà¸•à¸³à¸«à¸™à¸´à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¸‚à¸­à¸šà¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£à¹à¸šà¸•à¸—à¸™à¸¡à¸²à¸à¸Šà¸²à¸£à¹Œà¸ˆ1à¸„à¸£à¸±à¹‰à¸‡à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¹„à¸”à¹‰à¸¡à¸²à¸§à¸±à¸™à¹à¸£à¸à¸ˆà¸™à¸–à¸¶à¸‡à¸§à¸±à¸™à¸™à¸µà¹‰à¹à¸šà¸•à¸¢à¸±à¸‡à¹€à¸«à¸¥à¸·à¸­à¸­à¸µà¸50à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.8077051043510437\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹€à¸²à¸”à¸µà¸„à¹ˆà¸° à¸•à¸£à¸‡à¸›à¸ à¸ªà¹ˆà¸‡à¹„à¸§ à¹à¸•à¹ˆà¸«à¸±à¸1à¸”à¸²à¸§à¹€à¸žà¸£à¸²à¸°à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Ÿà¹‰à¸²à¹„à¸›à¹à¸™à¹ˆà¸§à¹ˆà¸ªà¹„à¸”à¹‰à¸ªà¸£à¸‚à¸²à¸§à¸¡à¸²à¹à¸—à¸™ à¹à¸•à¹ˆà¸§à¹ˆà¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸„à¹ˆà¸° à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¹†à¸”à¹‰à¸›à¸à¸•à¸´à¹€à¸¥à¸¢ à¹‚à¸­à¹€à¸„à¸¡à¸²à¸\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.8070789575576782\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸„à¹ˆà¸° à¸ à¸²à¸žà¸£à¸§à¸¡à¹‚à¸­à¹€à¸„à¹€à¸¥à¸¢ à¹„à¸”à¹‰à¸¡à¸µà¸¡ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¸„à¹ˆà¸° à¸ªà¸´à¸™à¸„à¹‰à¸²à¸ªà¹ˆà¸‡à¸­à¸­à¸ à¸šà¸£à¸´à¸«à¸²à¸£à¹‚à¸”à¸¢à¹€ à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸„à¹ˆà¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.8060870170593262\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸£à¸§à¸”à¹€à¸£à¹‡à¸§à¸—à¸±à¸™à¹ƒà¸ˆ à¹„à¸”à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡ à¹à¸žà¹‡à¸„à¹€à¸à¸ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢à¹à¸•à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¥à¸à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸² à¸£à¸²à¸„à¸²à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹‚à¸”à¸¢à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡ à¹‚à¸­à¸à¸²à¸ªà¸«à¸™à¹‰à¸²à¸„à¹ˆà¸­à¸¢à¸‹à¸·à¹‰à¸­à¹€à¸žà¸´à¹ˆà¸¡à¸™à¸°à¸„à¸£à¸±à¸š\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.8030720353126526\n",
      "\n",
      "comment: à¸”à¸µà¸„à¹ˆà¸° à¹à¸•à¹ˆà¹€à¸§à¸¥à¸²à¹‚à¸”à¸™à¸à¹‡à¸žà¸­à¸ªà¸‡à¹ˆà¸²à¸¢à¹€à¸à¸´à¸™à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¸„à¹ˆà¸° à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸à¹‡à¹ƒà¸Šà¹‰à¸‡à¹ˆà¸²à¸¢ à¸žà¸à¸žà¸²à¸‡à¹ˆà¸²à¸¢à¸ªà¸°à¸”à¸§à¸à¸„à¹ˆà¸° à¹à¸šà¸•à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸­à¸¶à¸”à¹€à¸¥à¸¢ à¹€à¸§à¸¥à¸²à¹€à¸›à¸´à¸”à¸›à¸´à¸”à¸à¸²à¸à¹‡à¹„à¸¡à¹ˆà¸à¹Šà¸­à¸à¹à¸à¹Šà¸‡ à¸‚à¸™à¸ªà¹ˆà¸‡à¹„à¸§à¸„à¹ˆà¸°\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.7954278588294983\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¸ à¸²à¸¢à¹ƒà¸™à¹„à¸¡à¹ˆà¸à¸µà¹ˆà¸§à¸±à¸™ à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸ªà¹ˆà¸‡à¸ˆà¸²à¸à¹ƒà¸™à¹„à¸—à¸¢à¹€à¸¥à¸¢ à¸žà¸±à¸ªà¸”à¸¸à¸à¸¥à¹ˆà¸­à¸‡ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸à¸°à¸‹à¸­à¸‡à¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸² à¹à¸•à¹ˆà¸„à¸²à¸”à¸§à¹ˆà¸²à¸™à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸›à¸à¸•à¸´ à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸­à¸°à¹„à¸£ à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆà¹à¸¥à¸°à¸ˆà¸°à¸à¸¥à¸±à¸šà¸¡à¸²à¸‹à¸·à¹‰à¸­à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 1.0\n",
      "predicted: 0.7935629487037659\n",
      "\n",
      "comment: à¸¥à¸­à¸‡à¹à¸¥à¹‰à¸§à¹‚à¸­à¹€à¸„.à¹„à¸Ÿà¸•à¸´à¸”à¸—à¸¸à¸à¸”à¸§à¸‡.à¸£à¸µà¹‚à¸¡à¸—à¹ƒà¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹‚à¸­à¹€à¸„à¸¡à¸µà¸–à¹ˆà¸²à¸™à¸•à¸´à¸´à¸”à¸¡à¸²à¹à¸¥à¹‰à¸§à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹€à¸¥à¸¢..à¹„à¸Ÿà¸ªà¸µà¸ªà¸±à¸™à¸ªà¸§à¸¢à¸‡à¸²à¸¡. à¹à¸žà¹‡à¸„à¸‚à¸­à¸‡à¸«à¹ˆà¸­à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸”à¸µà¸ªà¸´à¸™à¸„à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢.à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¸­à¸‡à¸„à¸£à¸š. à¸•à¸£à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡à¸‹à¸·à¹‰à¸­. à¸‚à¸™à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸µà¹‚à¸—à¸£à¹à¸ˆà¹‰à¸‡à¸à¹ˆà¸­à¸™à¹€à¸‚à¹‰à¸²à¸¡à¸²à¸ªà¹ˆà¸‡...\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7888125777244568\n",
      "\n",
      "comment: à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸„à¹ˆà¸° à¸£à¸²à¸„à¸²à¸à¹‡à¸–à¸¹à¸à¸”à¸µ à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸‡à¹ˆà¸²à¸¢à¸¡à¸²à¸ à¹€à¸§à¸¥à¸²à¹ƒà¸Šà¹‰à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸¥à¸·à¹ˆà¸™ à¹„à¸§à¸„à¹ˆà¸° à¸à¹‡à¸–à¸™à¸±à¸”à¸”à¸µ à¹„à¸§à¹‰à¸ˆà¸°à¸­à¸¸à¸”à¸«à¸™à¸¸à¸™à¹ƒà¸«à¸¡à¹ˆà¸™à¸°à¸„à¸°\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7836453914642334\n",
      "\n",
      "comment: à¸ªà¸§à¸¢à¸”à¸µà¸„à¹ˆà¸°à¹à¸•à¹ˆà¹à¸šà¸•à¸«à¸¡à¸”à¹„à¸§à¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢à¹€à¸¥à¹ˆà¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸›à¹‡à¸™à¸”à¹‰à¸§à¸¢à¸‡à¸‡à¹†à¸™à¸´à¸ªà¸™à¸¶à¸‡à¹ƒà¸ªà¹ˆà¹à¸¥à¹‰à¸§à¸§à¸±à¸”à¹„à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸«à¸£à¸·à¸­à¹€à¸£à¸²à¸‡à¸‡à¹†à¹„à¸›à¹€à¸­à¸‡à¸à¹‰à¸­à¹„à¸¡à¹ˆà¸£à¸¸à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹à¸à¹ˆà¸£à¸²à¸„à¸²à¸„à¹ˆà¸°à¸¥à¸¹à¸à¸­à¸¢à¸²à¸à¹„à¸”à¹‰à¸à¹‰à¸­à¹€à¸¥à¸¢à¸ˆà¸±à¸”à¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸”à¸¹à¸ªà¸±à¸à¸žà¸±à¸à¸§à¹ˆà¸²à¸ˆà¸°à¸—à¸™à¸—à¸²à¸™à¸¡à¸±à¹‰à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.779987096786499\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸¥à¸±à¸à¸©à¸“à¹Œà¸ªà¸§à¸¢à¸‡à¸²à¸¡à¸•à¸²à¸¡à¸›à¸ à¹à¸•à¹ˆà¸•à¸±à¸§à¹€à¸£à¸·à¸­à¸™à¹ƒà¸«à¸à¹ˆà¹„à¸›à¸«à¸™à¹ˆà¸­à¸¢ à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§ à¹à¸•à¹ˆà¸•à¸­à¸šà¹€à¹€à¸Šà¹‡à¸—à¸Šà¹‰à¸²à¸¡à¸²à¸ à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸‚à¸­à¸¥à¸­à¸‡à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¸ˆà¸°à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸”à¸µà¸‚à¸™à¸²à¸”à¹„à¸«à¸™\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.7777470946311951\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸£à¸‡à¸›à¸à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸¡à¸²à¸à¹†à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¹ƒà¸ˆà¸„à¸£à¸±à¸šà¸œà¸¡à¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸œ à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸ªà¸±à¹ˆà¸‡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šà¸£à¹‰à¸²à¸™à¸™à¸µà¹‰à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹†à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸„à¸¸à¹‰à¸¡à¸£à¸²à¸„à¸²à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢ à¸¡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7768676280975342\n",
      "\n",
      "comment: à¸•à¸´à¸”à¹†à¸«à¸¥à¸¸à¸”à¹†à¸‡à¸‡à¹† à¸Šà¸²à¸£à¹Œà¸ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¸šà¹‰à¸²à¸‡ à¹€à¸£à¸²à¹ƒà¸Šà¹‰à¹„à¸­à¹‚à¸Ÿà¸™11 à¸™à¸­à¸¢ à¸•à¸­à¸™à¸™à¸µà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆà¹€à¸žà¸£à¸²à¸°2à¹€à¸¡à¸•à¸£à¸£à¸¶à¸›à¹ˆà¸²à¸§ à¸–à¹‰à¸²1à¹€à¸¡à¸•à¸£à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² à¹à¸žà¹‡à¸„à¸”à¸µ à¸ªà¹ˆà¸‡à¹„à¸§\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7699492573738098\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µ à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¸•à¸²à¸¡à¸£à¸²à¸„à¸² à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¸§ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ à¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µà¸”à¸µ\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7602272629737854\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹à¸¥à¹‰à¸§ à¸Šà¸³à¸£à¸¸à¸”à¸„à¹ˆà¸° à¹à¸•à¸ à¸™à¹ˆà¸²à¸ˆà¸°à¸«à¹ˆà¸­à¹„à¸¡à¹ˆà¸”à¸µà¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸«à¹ˆà¸­à¸­à¸°à¹„à¸£à¹€à¸¥à¸¢ à¹ƒà¸ªà¹ˆà¹à¸„à¹ˆà¸–à¸¸à¸‡à¸¡à¸² à¹à¸šà¸šà¸™à¸µà¹‰à¸‚à¸­à¸‡à¸à¹‰à¸­à¸žà¸±à¸‡à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢à¸«à¸¡à¸”à¸ªà¸´à¸„à¸°\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7569918036460876\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¸¥à¸³à¹‚à¸žà¸‡à¹€à¸¥à¸°à¹€à¸—à¸°à¸¡à¸²à¸à¸•à¸±à¹‰à¸‡à¹€à¹€à¸•à¹ˆà¹€à¹€à¸à¸° à¸•à¹‰à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¸¥à¸³à¹‚à¸žà¸‡à¸•à¸¥à¸­à¸”à¹€à¸§à¸¥à¸²à¸–à¸¶à¸‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸«à¸¥à¸¸à¸”à¸šà¹ˆà¸­à¸¢\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7562223076820374\n",
      "\n",
      "comment: à¸›à¸¸à¹ˆà¸¡à¸à¸”à¸”à¹‰à¸²à¸™à¸‹à¹‰à¸²à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸•à¸´à¸”à¹†à¸­à¸°à¹„à¸£à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸à¸”à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸¥à¸‡ à¹€à¸¥à¸·à¹ˆà¸­à¸™à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹„à¸› à¸šà¸¥à¸¹à¸—à¸¹à¸˜à¸•à¸´à¸”à¸›à¸à¸•à¸´à¹à¸•à¹ˆà¹„à¸§à¹„à¸Ÿà¸¢à¸±à¸‡à¸•à¹ˆà¸­à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸¢ à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¹€à¸‡à¸´à¸™\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7497860789299011\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸”à¸³à¹„à¸”à¹‰à¸ªà¸µà¸™à¹‰à¸³à¹€à¸‡à¸´à¸™ à¸šà¸­à¸à¸žà¸™à¸±à¸à¸‡à¸²à¸™à¸ªà¹ˆà¸‡à¸œà¸´à¸” à¹à¸•à¹ˆà¸”à¸¹à¸ˆà¸²à¸à¸£à¸µà¸§à¸´à¸§à¸ªà¹ˆà¸‡à¸œà¸´à¸”à¸šà¹ˆà¸­à¸¢à¹„à¸›à¸™à¸°à¸„à¸°...\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.7425667643547058\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸‚à¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸”à¸µà¸¡à¸²à¸ à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸ªà¹ˆà¸‡à¸”à¸µà¸¡à¸²à¸à¹† à¸à¸²à¸£à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸ˆà¸²à¸à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸²à¸ à¸–à¸¹à¸à¹ƒà¸ˆà¸¡à¸²à¸à¹† à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡âœ¨\n",
      "actual: 0.8888888955116272\n",
      "predicted: 0.7361466884613037\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¸‚à¸­à¸‡à¸Šà¹‰à¸²à¸¡à¸² à¸£à¸­à¸¡à¸²à¸„à¸£à¸¶à¹ˆà¸‡à¹€à¸”à¸·à¸­à¸™à¸žà¸¶à¹ˆà¸‡à¸ˆà¸°à¹„à¸”à¹‰ à¸–à¹‰à¸²à¹ƒà¸„à¸£à¸£à¸µà¸šà¹„à¸›à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™à¸„à¸£à¸±à¸š\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7253915667533875\n",
      "\n",
      "comment: à¸ªà¸±à¸‡à¹€à¸à¸•à¸”à¸µà¹†à¸¡à¸µà¸£à¸­à¸¢à¹€à¸«à¸¡à¸·à¸­à¸™à¸–à¸¹à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¡à¸²à¹à¸¥à¹‰à¸§à¸”à¹‰à¸§à¸¢ à¸¡à¸±à¸™à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¹à¸¢à¹ˆà¹à¸¥à¸°à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸™à¹ˆà¸°à¸„à¹ˆà¸° à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸­à¸°à¹„à¸£à¹à¸•à¹ˆà¹à¸£à¸à¹à¸¥à¹‰à¸§ à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸ˆà¸°à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹„à¸”à¹‰à¸£à¸¶à¹€à¸›à¸¥à¹ˆà¸²ðŸ¥²ðŸ˜­\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7203196883201599\n",
      "\n",
      "comment: à¸Šà¸²à¸£à¹Œà¸ˆà¸Šà¹‰à¸²à¸¡à¸²à¸à¸„à¹ˆà¸° à¸Šà¸²à¸£à¹Œà¸ˆà¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¸™à¸­à¸™ à¸•à¸·à¹ˆà¸™à¸¡à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹€à¸•à¹‡à¸¡à¹€à¸¥à¸¢\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.7196280360221863\n",
      "\n",
      "comment: à¹à¸žà¹Šà¸„à¸‚à¸­à¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸ à¸à¸¥à¹ˆà¸­à¸‡à¸ªà¸²à¸¢à¸šà¸¸à¸šà¹„à¸›à¹€à¸à¸·à¸­à¸šà¸„à¸£à¸¶à¹ˆà¸‡ à¸ªà¸±à¹ˆà¸‡à¸„à¸£à¸±à¹‰à¸‡à¸™à¸µà¹‰à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¸ˆà¸°à¹„à¸¡à¹ˆà¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¹à¸¥à¹‰à¸§\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7185917496681213\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸‚à¸­à¸‡à¸¡à¸²à¸§à¸±à¸™à¸—à¸µà¹ˆ13 à¸§à¸±à¸™à¸™à¸µà¹‰à¸ªà¸±à¹ˆà¸™à¸„à¹‰à¸²à¸‡à¹à¸¥à¹‰à¸§à¸à¹‡à¸”à¸±à¸šà¹„à¸›à¹€à¸¥à¸¢ à¹€à¸›à¸´à¸”à¹„à¸¡à¹ˆà¸•à¸´à¸”à¸­à¸µà¸à¹€à¸¥à¸¢ à¸¥à¸­à¸‡à¸Šà¸²à¸£à¹Œà¸ˆà¹à¸¥à¹‰à¸§à¸à¹‡à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸•à¸­à¸šà¸ªà¸™à¸­à¸‡\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7179349660873413\n",
      "\n",
      "comment: à¹à¸¢à¹ˆ à¸£à¹‰à¸­à¸™à¸¡à¸²à¸à¹€à¸§à¸¥à¸²à¸Šà¸²à¸£à¹Œà¸ˆ à¸¡à¸µtype-c à¹à¸•à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¸­à¸­à¸à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸¡à¸µà¹„à¸§à¹‰à¹€à¸žà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7158589959144592\n",
      "\n",
      "comment: à¸£à¸¹à¸›à¸—à¸£à¸‡à¹€à¸—à¹ˆà¸”à¸µ à¸§à¸±à¸ªà¸”à¸¸à¸”à¸µ à¸šà¸²à¸‡à¸„à¸£à¸±à¹‰à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸¢à¸±à¸‡à¸«à¸™à¹ˆà¸§à¸‡à¸šà¹‰à¸²à¸‡à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢ à¹à¸•à¹ˆà¸à¹‡à¸–à¸·à¸­à¸§à¹ˆà¸²à¸ªà¸¡à¸£à¸²à¸„à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.7119811177253723\n",
      "\n",
      "comment: à¸•à¸°à¸¡à¸¸à¸•à¸°à¸¡à¸´à¸™à¹ˆà¸²à¸£à¸±à¸  à¹€à¸ªà¸µà¸¢à¸‡à¹à¸ˆà¹ˆà¸¡à¸”à¸µà¸„à¹ˆà¸°  à¸Šà¸­à¸šà¸¡à¸²à¸  à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.7092901468276978\n",
      "\n",
      "comment: à¹ƒà¸ªà¹ˆà¸‹à¸´à¸¡à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸±à¸à¸à¸²à¸“ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸¥à¸‡à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¸£à¹‰à¸²à¸™à¸„à¹‰à¸²à¸•à¸­à¸šà¸Šà¹‰à¸²\n",
      "actual: 0.7777777910232544\n",
      "predicted: 0.7047926187515259\n",
      "\n",
      "comment: à¸ªà¸ à¸²à¸žà¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¢à¸´à¸™à¸™à¸´à¸”à¸™à¸¶à¸‡à¹à¸•à¹ˆà¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¹‰à¸²à¸™à¹ƒà¸™à¸¢à¸±à¸‡à¹‚à¸­à¹€à¸„ à¹€à¸”à¸µà¹‹à¸¢à¸§à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸”à¸¹à¸à¹ˆà¸­à¸™à¸§à¹ˆà¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸›à¸à¸•à¸´à¸¡à¸±à¹Šà¸¢\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.7020278573036194\n",
      "\n",
      "comment: à¸—à¸±à¸à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸•à¸­à¸š à¹ƒà¸™à¸£à¸¹à¸›à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸ªà¸²à¸¢à¹à¸ˆà¹Šà¸ª à¸‚à¸­à¸‡à¸¡à¸²à¸–à¸¶à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸šà¸£à¸´à¸à¸²à¸£à¸”à¸¹à¹à¸¥\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.6873641610145569\n",
      "\n",
      "comment: à¸‚à¸­à¸‡à¸žà¸¶à¹ˆà¸‡à¹„à¸”à¹‰à¸¡à¸²à¹€à¸¡à¸·à¹ˆà¸­à¸§à¸²à¸™à¹ƒà¸Šà¹‰à¸•à¸­à¸™à¹€à¸Šà¹‰à¸²à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸œà¸¡à¸£à¸­à¸‚à¸­à¸‡à¸•à¸±à¹‰à¸‡à¸™à¸²à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¸‚à¸§à¸²\n",
      "actual: 0.6666666865348816\n",
      "predicted: 0.6797915101051331\n",
      "\n",
      "comment: à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸„à¸´à¸” à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¸„à¹Œà¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰ à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸žà¸¥à¸‡à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6703670620918274\n",
      "\n",
      "comment: à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸‚à¸²à¸§ à¹à¸•à¹ˆà¸ªà¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¸¡à¸²à¹à¸—à¸™ à¸—à¸²à¸‡à¸£à¹‰à¸²à¸™à¹„à¸¡à¹ˆà¸–à¸²à¸¡à¸à¹ˆà¸­à¸™ à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸±à¸™à¸ªà¸¡à¸±à¸¢ à¸ˆà¸±à¸šà¸–à¸™à¸±à¸”à¸¡à¸·à¸­\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6654304265975952\n",
      "\n",
      "comment: à¸ªà¹ˆà¸‡à¹„à¸§à¸¡à¸²à¸à¸§à¸±à¸™à¹€à¸”à¸µà¸¢à¸§à¸–à¸¶à¸‡à¸«à¸±à¸1à¸„à¸°à¹à¸™à¸™ à¹€à¸žà¸£à¸²à¸°à¹„à¸¡à¹ˆà¸«à¹‰à¸­à¸à¸±à¸™à¸›à¸£à¸°à¹à¸—à¸ à¸£à¸§à¸¡à¹à¸¥à¹‰à¸§à¸„à¸¸à¹‰à¸¡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.6644055247306824\n",
      "\n",
      "comment: à¸„à¸¸à¸“à¸ à¸²à¸žà¸”à¸µà¹€à¸à¸´à¸™à¸£à¸²à¸„à¸² à¸•à¹‰à¸­à¸‡à¸ªà¸±à¹ˆà¸‡à¸­à¸µà¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6601241230964661\n",
      "\n",
      "comment: à¹ƒà¸«à¹‰à¸ªà¸´à¸™à¸„à¹‰à¸²à¸¡à¸²à¸‹à¹‰à¸³à¹à¸¥à¸°à¹„à¸”à¹‰à¹„à¸¡à¹ˆà¸„à¸£à¸š à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸ˆà¸±à¸”à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸ªà¸±à¹ˆà¸‡\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.6542486548423767\n",
      "\n",
      "comment: à¸à¸¥à¹ˆà¸­à¸‡à¹€à¸¥à¹‡à¸à¸–à¸­à¸”à¹€à¸‚à¹‰à¸²à¸–à¸­à¸”à¸­à¸­à¸à¸¢à¸²à¸ à¹‚à¸—à¸£à¹„à¸¡à¹ˆà¸„à¹ˆà¸­à¸¢à¹€à¸ªà¸–à¸µà¸¢à¸£\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.6376268267631531\n",
      "\n",
      "comment: à¸«à¸¹à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¸¢à¸´à¸™à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¹„à¸¡à¹ˆà¸”à¸µà¹€à¸¥à¸¢ à¸à¸²à¸£à¹à¸žà¸„à¸à¸¥à¹ˆà¸­à¸‡à¸à¹‡à¹„à¸¡à¹ˆà¸ªà¸¡à¸›à¸£à¸°à¸à¸­à¸š à¸‚à¸²à¸”\n",
      "actual: 0.5555555820465088\n",
      "predicted: 0.6293125748634338\n",
      "\n",
      "comment: à¸§à¸±à¸ªà¸”à¸¸à¸à¹Šà¸­à¸‡à¹à¸à¹Šà¸‡à¸¡à¸²à¸ à¸ªà¸±à¹ˆà¸‡à¸ªà¸µà¸Šà¸¡à¸žà¸¹à¹„à¸”à¹‰à¸ªà¸µà¸Ÿà¹‰à¸²\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.6178131699562073\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸²à¸¢à¸Šà¸²à¸£à¹Œà¸•à¸ªà¹ˆà¸‡à¸¡à¸²à¸”à¹‰à¸§à¸¢\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.5673049092292786\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¸”à¸µà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.5538278222084045\n",
      "\n",
      "comment: à¸‚à¸™à¸ªà¹ˆà¸‡à¹à¸¢à¹ˆà¸¡à¸²à¸à¸„à¸£à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.5489386916160583\n",
      "\n",
      "comment: à¸œà¸´à¸”à¸«à¸§à¸±à¸‡à¸„à¸™à¸¥à¸°à¸£à¸¸à¹ˆà¸™à¸à¸±à¸™à¸Šà¸²à¸ˆà¹„à¸¡à¹ˆà¹ƒà¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.5402145981788635\n",
      "\n",
      "comment: à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸Šà¹‰à¸à¸²à¸£à¹„à¸¡à¹ˆà¹„à¸”à¹‰\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.5138363242149353\n",
      "\n",
      "comment: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹„à¸”à¹‰à¹à¸„à¹ˆà¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸„à¸±à¸š\n",
      "actual: 0.3333333432674408\n",
      "predicted: 0.49329549074172974\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸„à¸²à¸”à¸«à¸§à¸±à¸‡ à¹à¸•à¹ˆà¸à¹‡à¹„à¸¡à¹ˆà¹à¸¢à¹ˆà¸¡à¸²à¸\n",
      "actual: 0.0\n",
      "predicted: 0.4891034960746765\n",
      "\n",
      "comment: à¹„à¸”à¹‰à¸«à¸¹à¸Ÿà¸±à¸‡à¸¡à¸²à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§\n",
      "actual: 0.4444444477558136\n",
      "predicted: 0.4654242992401123\n",
      "\n",
      "comment: à¸žà¸­à¹ƒà¸Šà¹‰à¹„à¸”à¹‰\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.4430345892906189\n",
      "\n",
      "comment: à¹€à¸ªà¸µà¸¢à¸‡à¹€à¸šà¸²â€‹\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.4212802052497864\n",
      "\n",
      "comment: à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸£à¸²à¸„à¸²\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.41240325570106506\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸°à¹„à¸£à¸¡à¸²à¸à¹€à¸¥à¸¢\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.38852131366729736\n",
      "\n",
      "comment: à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸‹à¸·à¹‰à¸­\n",
      "actual: 0.1111111119389534\n",
      "predicted: 0.33466601371765137\n",
      "\n",
      "comment: à¸”à¸µà¸¡à¸²à¸à¹†\n",
      "actual: 0.2222222238779068\n",
      "predicted: 0.29639387130737305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model3\n",
    "tokenizer = tokenizer3\n",
    "\n",
    "# Define your loss function\n",
    "loss_fn = torch.nn.MSELoss()  # Change loss function to L1Loss for regression\n",
    "\n",
    "# Move your model to the device (CPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Set up gradient accumulation\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Define batch and epochs\n",
    "batch_size = 16  # Reduced batch size\n",
    "num_epochs = 3\n",
    "\n",
    "# Tokenize data and create dataloader\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    train_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=200,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "labels = torch.tensor(train_data['score_norm'].values, dtype=torch.float32)  # Convert labels to float32\n",
    "dataset = TensorDataset(encoded_data['input_ids'], encoded_data['attention_mask'], labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Fine-tune the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        step += 1\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {epoch_loss / step}')\n",
    "\n",
    "# model.save_pretrained(model_dir)\n",
    "# tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Preprocess the test data\n",
    "encoded_test_data = tokenizer.batch_encode_plus(\n",
    "    test_data['comment'].tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "test_labels = torch.tensor(test_data['score_norm'].values, dtype=torch.float32)\n",
    "test_dataset = TensorDataset(encoded_test_data['input_ids'], encoded_test_data['attention_mask'], test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model's predictions against the actual values\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = logits.squeeze(1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(labels.cpu().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print(f'Mean Absolute Error: {mae:.4f}')\n",
    "\n",
    "result_df = pd.DataFrame({'actual': actuals, 'predicted': predictions})\n",
    "\n",
    "form = pd.DataFrame(columns=['comment', 'actual', 'predicted'])\n",
    "count = 0\n",
    "for i in zip(test_data['comment'], result_df['actual'], result_df['predicted']):\n",
    "    form.loc[count] = [i[0], i[1], i[2]]\n",
    "    count += 1\n",
    "\n",
    "sorted_df = form.sort_values(by='predicted', ascending=False)\n",
    "\n",
    "for index, row in sorted_df.iterrows():\n",
    "    print(f\"comment: {row['comment']}\")\n",
    "    print(f\"actual: {row['actual']}\")\n",
    "    print(f\"predicted: {row['predicted']}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb52b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ab5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d2a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ebeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({\n",
    "    'comment': [\n",
    "        'à¸„à¸‡à¹‚à¸Šà¸„à¸£à¹‰à¸²à¸¢à¹€à¸­à¸‡ à¸Ÿà¸±à¸‡à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¸«à¸£à¸·à¸­à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¸à¹‡à¸¢à¸±à¸‡à¸‡à¸‡ à¸­à¸µà¸à¸‚à¹‰à¸²à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸±à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¹€à¸­à¸²à¹„à¸›à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸­à¸µà¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸à¹‡à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸‚à¹‰à¸²à¸‡à¹€à¸”à¸µà¸¢à¸§à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™',\n",
    "        'à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¸¡à¸²à¸ªà¸±à¸à¸žà¸±à¸à¸”à¸µà¸¡à¸²à¸à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ªà¸µà¸¢à¸‡à¹„à¸¡à¹ˆà¹à¸•à¸à¹€à¸šà¸ªà¸«à¸™à¸±à¸à¸Ÿà¸±à¸‡à¹€à¸žà¸¥à¸‡à¹€à¸ªà¸µà¸¢à¸‡à¸”à¸µà¸¡à¸²à¸à¸¡à¸µà¸•à¸³à¸«à¸™à¸´à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢à¸•à¸£à¸‡à¸‚à¸­à¸šà¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸£à¹à¸šà¸•à¸—à¸™à¸¡à¸²à¸à¸Šà¸²à¸£à¹Œà¸ˆ1à¸„à¸£à¸±à¹‰à¸‡à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆà¹„à¸”à¹‰à¸¡à¸²à¸§à¸±à¸™à¹à¸£à¸à¸ˆà¸™à¸–à¸¶à¸‡à¸§à¸±à¸™à¸™à¸µà¹‰à¹à¸šà¸•à¸¢à¸±à¸‡à¹€à¸«à¸¥à¸·à¸­à¸­à¸µà¸50à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œ',\n",
    "        'à¸„à¸¸à¸“à¸ à¸²à¸žà¹à¸¢à¹ˆà¸Šà¸²à¸£à¹Œà¸ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹à¸¥à¸°à¹„à¸¡à¹ˆà¸Šà¸”à¹ƒà¸Šà¹‰à¸„à¸·à¸™',\n",
    "        'à¸¡à¸µà¸£à¸­à¸¢à¸£à¹‰à¸²à¸§',\n",
    "        'à¸•à¹‰à¸­à¸‡à¸Šà¸²à¸£à¸ˆà¹Œà¹à¸šà¸•à¸à¹ˆà¸­à¸™à¹€à¸›à¸´à¸” à¹€à¸›à¸´à¸”à¹à¸¥à¹‰à¸§à¸Ÿà¸±à¸‡à¹€à¸žà¸¥à¸‡à¹„à¸”à¹‰à¸”à¸µ à¹ƒà¸ªà¹ˆà¸à¸²à¸£à¹Œà¸”à¹à¸¥à¹‰à¸§à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¹ˆà¸™à¹„à¸”à¹‰à¸›à¸¸à¹ˆà¸¡à¸à¸” à¸‡à¸‡à¹† à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢ à¸›à¸¸à¹ˆà¸¡à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™ à¸à¸”à¸ªà¸±à¹‰à¸™ à¸à¸”à¸¢à¸²à¸§ à¹ƒà¸«à¹‰à¸œà¸¥à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™',\n",
    "        'à¹„à¸”à¹‰à¸£à¸±à¸šà¸ªà¸´à¸™à¸„à¹‰à¸²à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¸„à¸£à¸±à¸šâ€‹ à¸ªà¹ˆà¸‡à¹€à¸£à¹‡à¸§à¸”à¸µâ€‹ à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹à¸žà¸‡â€‹ à¹ƒà¸„à¸£à¸ªà¸™à¹ƒà¸ˆà¸ªà¸±à¹ˆà¸‡à¸‹à¸·à¹‰à¸­à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸šâ€‹ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰à¹à¸•à¹ˆà¸„à¸´à¸”à¸§à¹ˆà¸²à¸„à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²'\n",
    "    ],\n",
    "    'score': [5, 7, 6, 4, 5, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e1a3df4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "pythainlp/ulmfit-base-thai is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:259\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/pythainlp/ulmfit-base-thai/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\file_download.py:1160\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1160\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\file_download.py:1501\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[0;32m   1492\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1493\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1494\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:291\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    283\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     )\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6436804c-33accc0645f73cef0500c486)\n\nRepository Not Found for url: https://huggingface.co/pythainlp/ulmfit-base-thai/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpythainlp/ulmfit-base-thai\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:619\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[1;32m--> 619\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[0;32m    621\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:463\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03mLoads the tokenizer configuration from a pretrained model tokenizer configuration.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m    462\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 463\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    410\u001b[0m         path_or_repo_id,\n\u001b[0;32m    411\u001b[0m         filename,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    420\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    421\u001b[0m     )\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m     )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: pythainlp/ulmfit-base-thai is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd163fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
