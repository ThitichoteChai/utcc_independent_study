{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e408034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: C:\\Users\\Pop\\Documents\\GitHub\\utcc_independent_study\\training\\..\\data\\300_data_pop.xlsx\n",
      "data_size: 318\n",
      "variable: data train_data test_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>พลังเสียงชัดเจน โอเคเลย</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>คุณภาพ: ดีให้ฟิล์มไม่ตรง สั่ง14 happy birthday...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>คุณภาพ: ภาพรวมดี แข็งแรงขาตั้งแข็งแรง ปรับระดั...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>เชื่อมต่อกับคอมไม่ได้ ทางร้านไม่แก้ปัญหาให้เลย</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>พึ่งได้หยิบมาใช้งาน สังเกตุว่ามีรอยร้าว แต่ไม่...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>กล่องเหมือนโดนแกะแล้ว สตกเผยอๆนิดหน่อย แต่ของข...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>สินค้าใช้การไม่ได้</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>สินค้ามีคุณภาพ คุณภาพดี การจัดส่งค่อนข้างรวดเร...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ก็ตามราคาแหละ แต่เคยซื้อยี่ห้อนี้ มันเคยดีกว่านี้</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>คุณภาพ: ดีการจัดส่งสินค้า ตรงตามเวลาที่กำหนด ส...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  score\n",
       "281                            พลังเสียงชัดเจน โอเคเลย      3\n",
       "236  คุณภาพ: ดีให้ฟิล์มไม่ตรง สั่ง14 happy birthday...      5\n",
       "245  คุณภาพ: ภาพรวมดี แข็งแรงขาตั้งแข็งแรง ปรับระดั...      6\n",
       "90      เชื่อมต่อกับคอมไม่ได้ ทางร้านไม่แก้ปัญหาให้เลย      6\n",
       "51   พึ่งได้หยิบมาใช้งาน สังเกตุว่ามีรอยร้าว แต่ไม่...      7\n",
       "..                                                 ...    ...\n",
       "87   กล่องเหมือนโดนแกะแล้ว สตกเผยอๆนิดหน่อย แต่ของข...      7\n",
       "184                                 สินค้าใช้การไม่ได้      3\n",
       "168  สินค้ามีคุณภาพ คุณภาพดี การจัดส่งค่อนข้างรวดเร...      6\n",
       "15   ก็ตามราคาแหละ แต่เคยซื้อยี่ห้อนี้ มันเคยดีกว่านี้      1\n",
       "238  คุณภาพ: ดีการจัดส่งสินค้า ตรงตามเวลาที่กำหนด ส...      5\n",
       "\n",
       "[318 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run data_read.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eceaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, vocab2index = preprocess_data(data)\n",
    "data = data[['comment', 'score', 'encoded']]\n",
    "\n",
    "X = list(data['encoded'])\n",
    "Y = list(data['score'])\n",
    "batch_size = 16\n",
    "\n",
    "train_dl, val_dl, vocab_size, embedding_dim, hidden_dim = create_datasets(X, Y, vocab2index, batch_size)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a047c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_regr(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        # print('epochs:', i, end=' ')\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.l1_loss(y_pred, y.unsqueeze(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss = validation_metrics_regr(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train mae %.4f val mae %.4f\" % (sum_loss/total, val_loss))\n",
    "            \n",
    "def validation_metrics_regr (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.float()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.l1_loss(y_hat, y.unsqueeze(-1))\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91b3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_ idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])\n",
    "\n",
    "class RNN_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        rnn_out, ht = self.rnn(x)\n",
    "        return self.linear(ht[-1])\n",
    "\n",
    "class CNN_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, filter_sizes, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(embedding_dim, num_filters, fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.linear1 = nn.Linear(num_filters * len(filter_sizes), hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = x.permute(0, 2, 1) # switch to (batch_size, embedding_dim, sequence_length)\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_output = conv(x)\n",
    "            conv_output = F.relu(conv_output)\n",
    "            max_pool_output = F.max_pool1d(conv_output, conv_output.size()[2])\n",
    "            conv_outputs.append(max_pool_output.squeeze(-1))\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        return self.linear2(x)\n",
    "    \n",
    "class DNN_regr(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8acd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mae 4.9043 val mae 5.0868\n",
      "train mae 4.2082 val mae 2.9374\n",
      "train mae 2.0928 val mae 1.8208\n",
      "train mae 2.0956 val mae 1.8255\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(lstm_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1ffa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mae 4.7792 val mae 4.8716\n",
      "train mae 2.3496 val mae 2.1875\n",
      "train mae 2.2489 val mae 2.1324\n",
      "train mae 2.2302 val mae 1.9782\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNN_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(rnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d234c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mae 4.0723 val mae 3.6759\n",
      "train mae 1.2372 val mae 1.0450\n",
      "train mae 1.0450 val mae 0.9666\n",
      "train mae 0.8474 val mae 0.9335\n"
     ]
    }
   ],
   "source": [
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]\n",
    "cnn_model = CNN_regr(vocab_size, embedding_dim, num_filters, filter_sizes, hidden_dim)\n",
    "train_model_regr(cnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63351013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mae 4.8941 val mae 5.0823\n",
      "train mae 4.7682 val mae 4.9340\n",
      "train mae 4.4411 val mae 4.5771\n",
      "train mae 3.6692 val mae 3.6969\n"
     ]
    }
   ],
   "source": [
    "dnn_model = DNN_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(dnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "# Read the test excerpts\n",
    "test_data = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Apply the same encoding as the train texts\n",
    "test_data['encoded'] = test_data['excerpt'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "idx, excerpts_test = test_data['id'], test_data['encoded']\n",
    "\n",
    "X_test = [excerpts_test[i][0] for i in range(len(test_data))]\n",
    "l_test = [excerpts_test[i][1] for i in range(len(test_data))]\n",
    "X_test = torch.LongTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115de37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
