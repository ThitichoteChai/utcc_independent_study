{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419b702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: C:\\Users\\POP PC\\Documents\\GitHub\\utcc_independent_study\\training\\..\\data\\300_data_pop.xlsx\n",
      "data_size: 318\n",
      "variable: data train_data test_data\n"
     ]
    }
   ],
   "source": [
    "%run data_read.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e408034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 1322\n",
      "num_words after: 641\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score_norm</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ตัวหูฟังมีรอยแตกทั้ง2ข้าง ตอนนี้ยังไม่มีผลต่อก...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>[2, 3, 4, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ซื้อสินค้าไปดูไม่ค่อยแข็งแรง ใช้ไม่ได้ด้วยค่ะ ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[22, 23, 1, 24, 25, 8, 26, 27, 28, 8, 1, 8, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>สินค้าใช้ไม่ได้ ร้านค้าแจ้งไม่ต้องกดในระบบ พอเ...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[23, 26, 8, 47, 48, 49, 50, 51, 52, 8, 53, 35,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ของพึ่งได้มาเมื่อวานใช้ตอนเช้าฟังได้แค่ข้างเดี...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[58, 59, 60, 61, 62, 63, 64, 20, 65, 66, 67, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ประสิทธิภาพ: ใช้พูดคุยไม่ได้เสียงเบามาก ,คนฟัง...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>[68, 69, 8, 62, 1, 11, 70, 71, 72, 73, 8, 74, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  score_norm   \n",
       "0  ตัวหูฟังมีรอยแตกทั้ง2ข้าง ตอนนี้ยังไม่มีผลต่อก...    0.444444  \\\n",
       "1  ซื้อสินค้าไปดูไม่ค่อยแข็งแรง ใช้ไม่ได้ด้วยค่ะ ...    1.000000   \n",
       "2  สินค้าใช้ไม่ได้ ร้านค้าแจ้งไม่ต้องกดในระบบ พอเ...    0.888889   \n",
       "3  ของพึ่งได้มาเมื่อวานใช้ตอนเช้าฟังได้แค่ข้างเดี...    0.666667   \n",
       "4  ประสิทธิภาพ: ใช้พูดคุยไม่ได้เสียงเบามาก ,คนฟัง...    0.777778   \n",
       "\n",
       "                                             encoded  \n",
       "0  [2, 3, 4, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 8,...  \n",
       "1  [22, 23, 1, 24, 25, 8, 26, 27, 28, 8, 1, 8, 29...  \n",
       "2  [23, 26, 8, 47, 48, 49, 50, 51, 52, 8, 53, 35,...  \n",
       "3  [58, 59, 60, 61, 62, 63, 64, 20, 65, 66, 67, 5...  \n",
       "4  [68, 69, 8, 62, 1, 11, 70, 71, 72, 73, 8, 74, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, vocab2index = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac161df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data['encoded'])\n",
    "Y = list(data['score_norm'])\n",
    "batch_size = 16\n",
    "train_dl, val_dl, vocab_size, embedding_dim, hidden_dim = create_datasets(X, Y, vocab2index, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a047c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_regr(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        # print('epochs:', i, end=' ')\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.mse_loss(y_pred, y.unsqueeze(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss = validation_metrics_regr(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train mse %.4f val rmse %.4f\" % (sum_loss/total, val_loss))\n",
    "\n",
    "def validation_metrics_regr (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.float()\n",
    "        y_hat = model(x, l)\n",
    "        loss = np.sqrt(F.mse_loss(y_hat, y.unsqueeze(-1)).item())\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91b3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])\n",
    "\n",
    "class RNN_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        rnn_out, ht = self.rnn(x)\n",
    "        return self.linear(ht[-1])\n",
    "\n",
    "class CNN_regr(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, num_filters, filter_sizes, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(embedding_dim, num_filters, fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.linear1 = nn.Linear(num_filters * len(filter_sizes), hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = x.permute(0, 2, 1) # switch to (batch_size, embedding_dim, sequence_length)\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_output = conv(x)\n",
    "            conv_output = F.relu(conv_output)\n",
    "            max_pool_output = F.max_pool1d(conv_output, conv_output.size()[2])\n",
    "            conv_outputs.append(max_pool_output.squeeze(-1))\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        return self.linear2(x)\n",
    "    \n",
    "class DNN_regr(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8acd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse 0.3014 val rmse 0.5358\n",
      "train mse 0.1090 val rmse 0.2552\n",
      "train mse 0.0775 val rmse 0.2419\n",
      "train mse 0.0769 val rmse 0.2415\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(lstm_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1ffa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse 0.2945 val rmse 0.4883\n",
      "train mse 0.0773 val rmse 0.2425\n",
      "train mse 0.0782 val rmse 0.2420\n",
      "train mse 0.0769 val rmse 0.2420\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNN_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(rnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d234c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse 0.0797 val rmse 0.1827\n",
      "train mse 0.0439 val rmse 0.1419\n",
      "train mse 0.0342 val rmse 0.1391\n",
      "train mse 0.0238 val rmse 0.1432\n"
     ]
    }
   ],
   "source": [
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]\n",
    "cnn_model = CNN_regr(vocab_size, embedding_dim, num_filters, filter_sizes, hidden_dim)\n",
    "train_model_regr(cnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63351013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse 0.4187 val rmse 0.6414\n",
      "train mse 0.2830 val rmse 0.5157\n",
      "train mse 0.1121 val rmse 0.3058\n",
      "train mse 0.0527 val rmse 0.2135\n"
     ]
    }
   ],
   "source": [
    "dnn_model = DNN_regr(vocab_size, embedding_dim, hidden_dim)\n",
    "train_model_regr(dnn_model, epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "# Read the test excerpts\n",
    "test_data = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Apply the same encoding as the train texts\n",
    "test_data['encoded'] = test_data['excerpt'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "idx, excerpts_test = test_data['id'], test_data['encoded']\n",
    "\n",
    "X_test = [excerpts_test[i][0] for i in range(len(test_data))]\n",
    "l_test = [excerpts_test[i][1] for i in range(len(test_data))]\n",
    "X_test = torch.LongTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115de37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
